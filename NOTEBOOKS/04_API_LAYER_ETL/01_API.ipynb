{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GOLD TO API LAYER\n",
    "\n",
    "### API Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T06:38:53.549503Z",
     "iopub.status.busy": "2024-09-06T06:38:53.549017Z",
     "iopub.status.idle": "2024-09-06T06:38:53.941679Z",
     "shell.execute_reply": "2024-09-06T06:38:53.941030Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from ETLTools import GlobalPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T06:38:53.944311Z",
     "iopub.status.busy": "2024-09-06T06:38:53.944058Z",
     "iopub.status.idle": "2024-09-06T06:38:53.948430Z",
     "shell.execute_reply": "2024-09-06T06:38:53.947876Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define file paths using GlobalPath\n",
    "current_holding_records_file_path = GlobalPath(\n",
    "    \"DATA/GOLD/Holdings/CurrentHoldings_data.csv\"\n",
    ")\n",
    "stockprice_silver_file_path = GlobalPath(\n",
    "    \"DATA/SILVER/StockPrice/StockPrice_data.csv\"\n",
    ")\n",
    "holdingshistory_gold_file_path = GlobalPath(\n",
    "    \"DATA/GOLD/Holdings/HoldingsHistory_data.csv\"\n",
    ")\n",
    "profitloss_gold_file_path = GlobalPath(\n",
    "    \"DATA/GOLD/ProfitLoss/ProfitLoss_data.csv\"\n",
    ")\n",
    "api_file_path = GlobalPath(\"DATA/API/API_data.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and process holdings data from the GOLD layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T06:38:53.950799Z",
     "iopub.status.busy": "2024-09-06T06:38:53.950474Z",
     "iopub.status.idle": "2024-09-06T06:38:53.958841Z",
     "shell.execute_reply": "2024-09-06T06:38:53.958363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded GOLD Layer datetime data from: C:\\Users\\prashant.tripathi\\Code\\PortfolioTracker\\DATA\\GOLD\\Holdings\\CurrentHoldings_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Load holdings data from GOLD layer\n",
    "df_current_holding = pd.read_csv(current_holding_records_file_path.path)\n",
    "df_current_holding[\"datetime\"] = pd.to_datetime(df_current_holding[\"datetime\"])\n",
    "print(\n",
    "    f\"Loaded GOLD Layer datetime data from: {current_holding_records_file_path.path}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T06:38:53.960900Z",
     "iopub.status.busy": "2024-09-06T06:38:53.960721Z",
     "iopub.status.idle": "2024-09-06T06:38:53.971502Z",
     "shell.execute_reply": "2024-09-06T06:38:53.970908Z"
    }
   },
   "outputs": [],
   "source": [
    "# Group by scrip_name, symbol, exchange, and segment to calculate totals and min datetime\n",
    "df_grouped = (\n",
    "    df_current_holding.groupby([\"scrip_name\", \"symbol\", \"exchange\", \"segment\"])\n",
    "    .agg(\n",
    "        total_quantity=(\"quantity\", \"sum\"),\n",
    "        total_amount=(\"amount\", \"sum\"),\n",
    "        min_datetime=(\"datetime\", \"min\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Calculate average price\n",
    "df_grouped[\"avg_price\"] = (\n",
    "    df_grouped[\"total_amount\"] / df_grouped[\"total_quantity\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and process stock prices from the SILVER layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T06:38:53.973831Z",
     "iopub.status.busy": "2024-09-06T06:38:53.973514Z",
     "iopub.status.idle": "2024-09-06T06:38:53.984903Z",
     "shell.execute_reply": "2024-09-06T06:38:53.984353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded SILVER Layer stock price data from: C:\\Users\\prashant.tripathi\\Code\\PortfolioTracker\\DATA\\SILVER\\StockPrice\\StockPrice_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Load stock prices data from SILVER layer\n",
    "df_stockprice = pd.read_csv(stockprice_silver_file_path.path)\n",
    "print(\n",
    "    f\"Loaded SILVER Layer stock price data from: {stockprice_silver_file_path}\"\n",
    ")\n",
    "\n",
    "# Convert the 'date' column to datetime type\n",
    "df_stockprice[\"date\"] = pd.to_datetime(df_stockprice[\"date\"])\n",
    "\n",
    "# Extract the latest closing price for each symbol\n",
    "df_stockprice[\"close_price\"] = df_stockprice[\"close\"]\n",
    "idx = df_stockprice.groupby(\"symbol\")[\"date\"].idxmax()\n",
    "df_stockprice = df_stockprice.loc[idx].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge data and calculate PnL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T06:38:53.987089Z",
     "iopub.status.busy": "2024-09-06T06:38:53.986774Z",
     "iopub.status.idle": "2024-09-06T06:38:53.995564Z",
     "shell.execute_reply": "2024-09-06T06:38:53.994991Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merge the grouped holdings data with the latest stock price data on symbol\n",
    "df_grouped = pd.merge(\n",
    "    df_grouped,\n",
    "    df_stockprice[[\"symbol\", \"close_price\"]],\n",
    "    on=\"symbol\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "# Calculate the close amount and PnL amount for each entry\n",
    "df_grouped[\"close_amount\"] = (\n",
    "    df_grouped[\"close_price\"] * df_grouped[\"total_quantity\"]\n",
    ")\n",
    "df_grouped[\"pnl_amount\"] = (\n",
    "    df_grouped[\"close_amount\"] - df_grouped[\"total_amount\"]\n",
    ")\n",
    "\n",
    "# Round numerical columns to 2 decimal places\n",
    "df_grouped = df_grouped.round(2)\n",
    "\n",
    "# Sort and format the DataFrame\n",
    "df_grouped = df_grouped.sort_values(by=[\"segment\", \"symbol\"]).reset_index(\n",
    "    drop=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T06:38:53.997917Z",
     "iopub.status.busy": "2024-09-06T06:38:53.997585Z",
     "iopub.status.idle": "2024-09-06T06:38:54.009490Z",
     "shell.execute_reply": "2024-09-06T06:38:54.008897Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare a list to hold the final result\n",
    "current_holding = []\n",
    "for _, row in df_grouped.iterrows():\n",
    "    # Filter current holdings matching each grouped entry\n",
    "    df_filtered = df_current_holding[\n",
    "        (df_current_holding[\"scrip_name\"] == row[\"scrip_name\"])\n",
    "        & (df_current_holding[\"symbol\"] == row[\"symbol\"])\n",
    "        & (df_current_holding[\"exchange\"] == row[\"exchange\"])\n",
    "        & (df_current_holding[\"segment\"] == row[\"segment\"])\n",
    "    ]\n",
    "\n",
    "    # Convert the row to a dictionary and add historical data\n",
    "    row = row.to_dict()\n",
    "    row[\"history\"] = df_filtered.to_dict(orient=\"records\")\n",
    "    current_holding.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T06:38:54.011655Z",
     "iopub.status.busy": "2024-09-06T06:38:54.011327Z",
     "iopub.status.idle": "2024-09-06T06:38:54.027372Z",
     "shell.execute_reply": "2024-09-06T06:38:54.026855Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded GOLD Layer holdings data from: C:\\Users\\prashant.tripathi\\Code\\PortfolioTracker\\DATA\\GOLD\\Holdings\\HoldingsHistory_data.csv\n"
     ]
    }
   ],
   "source": [
    "df_holdings = pd.read_csv(holdingshistory_gold_file_path.path)\n",
    "df_holdings[\"date\"] = pd.to_datetime(df_holdings[\"date\"]).dt.date\n",
    "print(f\"Loaded GOLD Layer holdings data from: {holdingshistory_gold_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T06:38:54.029807Z",
     "iopub.status.busy": "2024-09-06T06:38:54.029352Z",
     "iopub.status.idle": "2024-09-06T06:38:54.040022Z",
     "shell.execute_reply": "2024-09-06T06:38:54.039577Z"
    }
   },
   "outputs": [],
   "source": [
    "df_holdings_trands = (\n",
    "    df_holdings.groupby(\"date\")[\n",
    "        [\n",
    "            \"holding_amount\",\n",
    "            \"open_amount\",\n",
    "            \"high_amount\",\n",
    "            \"low_amount\",\n",
    "            \"close_amount\",\n",
    "        ]\n",
    "    ]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "df_holdings_trands = df_holdings_trands.round(2)\n",
    "df_holdings_trands = df_holdings_trands.rename(\n",
    "    columns={\n",
    "        col: col.replace(\"_amount\", \"\") for col in df_holdings_trands.columns\n",
    "    }\n",
    ")\n",
    "df_holdings_trands = df_holdings_trands[\n",
    "    [\n",
    "        \"date\",\n",
    "        \"open\",\n",
    "        \"high\",\n",
    "        \"low\",\n",
    "        \"close\",\n",
    "        \"holding\",\n",
    "    ]\n",
    "]\n",
    "df_holdings_trands = df_holdings_trands.sort_values(by=[\"date\"]).reset_index(\n",
    "    drop=True\n",
    ")\n",
    "holdings_trands = df_holdings_trands.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read GOLD Layer ProfitLoss data from: C:\\Users\\prashant.tripathi\\Code\\PortfolioTracker\\DATA\\GOLD\\ProfitLoss\\ProfitLoss_data.csv\n"
     ]
    }
   ],
   "source": [
    "print(f\"Read GOLD Layer ProfitLoss data from: {profitloss_gold_file_path}\")\n",
    "## PRESENTATION LAYER\n",
    "df = pd.read_csv(profitloss_gold_file_path.path)\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "df[\"stock_name\"] = df.apply(\n",
    "    lambda row: (\n",
    "        row[\"symbol\"] if row[\"symbol\"] == \"NIFTY\" else row[\"scrip_name\"]\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Ensure the columns are datetime64 dtype\n",
    "df[\"open_datetime\"] = pd.to_datetime(df[\"open_datetime\"])\n",
    "df[\"close_datetime\"] = pd.to_datetime(df[\"close_datetime\"])\n",
    "\n",
    "# Calculate the difference in days\n",
    "df[\"days\"] = (df[\"close_datetime\"] - df[\"open_datetime\"]).dt.days\n",
    "\n",
    "# Sort and format the DataFrame\n",
    "df = df.sort_values(by=[\"segment\", \"symbol\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by 'name' and 'type'\n",
    "result = []\n",
    "grouped = df.groupby([\"segment\", \"exchange\", \"symbol\", \"stock_name\"])\n",
    "\n",
    "for (segment, exchange, symbol, stock_name), group in grouped:\n",
    "    group_dict = {\n",
    "        \"segment\": segment,\n",
    "        \"exchange\": exchange,\n",
    "        \"symbol\": symbol,\n",
    "        \"stock_name\": stock_name,\n",
    "        \"days\": (\n",
    "            group[\"close_datetime\"].max() - group[\"open_datetime\"].min()\n",
    "        ).days,\n",
    "        \"quantity\": group[\"quantity\"].sum(),\n",
    "        \"avg_price\": round(\n",
    "            group[\"open_amount\"].sum() / group[\"quantity\"].sum(), 2\n",
    "        ),\n",
    "        \"sell_price\": round(\n",
    "            group[\"close_amount\"].sum() / group[\"quantity\"].sum(), 2\n",
    "        ),\n",
    "        \"pnl\": group[\"pnl_amount\"].sum(),\n",
    "        \"history\": group[\n",
    "            [\n",
    "                \"scrip_name\",\n",
    "                \"position\",\n",
    "                \"quantity\",\n",
    "                \"days\",\n",
    "                \"open_datetime\",\n",
    "                \"open_price\",\n",
    "                \"open_amount\",\n",
    "                \"close_datetime\",\n",
    "                \"close_price\",\n",
    "                \"close_amount\",\n",
    "                \"pnl_amount\",\n",
    "                \"pnl_percentage\",\n",
    "            ]\n",
    "        ].to_dict(orient=\"records\"),\n",
    "    }\n",
    "    result.append(group_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare final output dictionary and write to JSON file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T06:38:54.042360Z",
     "iopub.status.busy": "2024-09-06T06:38:54.041901Z",
     "iopub.status.idle": "2024-09-06T06:38:54.063576Z",
     "shell.execute_reply": "2024-09-06T06:38:54.063006Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to C:\\Users\\prashant.tripathi\\Code\\PortfolioTracker\\DATA\\API\\API_data.json\n"
     ]
    }
   ],
   "source": [
    "# Create the final output dictionary for the API\n",
    "output = {\n",
    "    \"financial_summary\": {\n",
    "        \"invested_value\": round(df_grouped[\"total_amount\"].sum(), 2),\n",
    "        \"current_value\": round(df_grouped[\"close_amount\"].sum(), 2),\n",
    "        \"pnl_value\": round(df_grouped[\"pnl_amount\"].sum(), 2),\n",
    "    },\n",
    "    \"current_holding_data\": current_holding,\n",
    "    \"holdings_trands_data\": holdings_trands,\n",
    "    \"profitloss_summary\": {\n",
    "        \"invested_value\": round(df[\"open_amount\"].sum(), 2),\n",
    "        \"sold_value\": round(df[\"close_amount\"].sum(), 2),\n",
    "        \"pnl_value\": round(df[\"pnl_amount\"].sum(), 2),\n",
    "    },\n",
    "    \"profit_loss_data\": result,\n",
    "}\n",
    "\n",
    "# Write the result to a JSON file\n",
    "with open(api_file_path.path, \"w\") as json_file:\n",
    "    json.dump(output, json_file, indent=4, default=str)\n",
    "\n",
    "print(f\"Data written to {api_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_debug": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
