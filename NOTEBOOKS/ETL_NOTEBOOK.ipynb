{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "from common_utilities import replace_punctuation_from_columns,TradeHistory,stock_names_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Folder and File path\n",
    "\n",
    "bronze_path = pathlib.Path(\"../DATA/BRONZE/\")\n",
    "silver_path = pathlib.Path(\"../DATA/SILVER/\")\n",
    "gold_path   = pathlib.Path(\"../DATA/GOLD/\")\n",
    "\n",
    "bronze_trade_history_file_path = bronze_path.joinpath(\"TRADE_HISTORY\")\n",
    "bronze_stock_price_file_path = bronze_path.joinpath(\"STOCK_PRICE\")\n",
    "\n",
    "silver_file_path = silver_path.joinpath(\"TradeHistory.json\")\n",
    "gold_file_path = gold_path.joinpath(\"TradeHistory.json\")\n",
    "gold_stock_price_file_path = gold_path.joinpath(\"StockPrice.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 42 entries, 39 to 40\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   date             42 non-null     object \n",
      " 1   company          42 non-null     object \n",
      " 2   amount           42 non-null     float64\n",
      " 3   exchange         42 non-null     object \n",
      " 4   segment          42 non-null     object \n",
      " 5   scrip_code       42 non-null     int64  \n",
      " 6   instrument_type  42 non-null     object \n",
      " 7   strike_price     42 non-null     object \n",
      " 8   expiry           42 non-null     object \n",
      " 9   trade_num        40 non-null     float64\n",
      " 10  trade_time       40 non-null     object \n",
      " 11  side             42 non-null     object \n",
      " 12  quantity         42 non-null     int64  \n",
      " 13  price            42 non-null     float64\n",
      "dtypes: float64(3), int64(2), object(9)\n",
      "memory usage: 6.0+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33936/1705155700.py:18: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_silver = pd.concat(dfs, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "## BRONZE TO SILVER\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# List all CSV files in the folder\n",
    "bronze_csv_files = bronze_trade_history_file_path.glob('*.csv')\n",
    "\n",
    "# Loop through the CSV files\n",
    "for file_path in bronze_csv_files:\n",
    "    # Read the CSV file \n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Append the DataFrame to the list\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "df_silver = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "df_silver.columns = replace_punctuation_from_columns(df_silver.columns)\n",
    "df_silver.dropna(how='all', axis=1, inplace=True) \n",
    "df_silver = df_silver[df_silver['segment'] == 'EQ']\n",
    "\n",
    "df_silver['date'] = pd.to_datetime(df_silver['date']).astype('str')\n",
    "df_silver['scrip_code'] = df_silver['scrip_code'].astype('int64')\n",
    "df_silver['expiry'] = pd.to_datetime(df_silver['expiry']).astype('str')\n",
    "df_silver['quantity'] = df_silver['quantity'].astype('int64')\n",
    "\n",
    "# sort the dataframe by date\n",
    "df_silver = df_silver.sort_values(by=[\"date\",\"trade_time\",\"company\"])\n",
    "\n",
    "# Save the result as a json file\n",
    "df_silver.to_json(silver_file_path, orient=\"records\",indent=4)\n",
    "df_silver.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'DatetimeArray' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m df_silver[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstock_name\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df_silver[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscrip_code\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(stock_names_dict)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# combine 'date' and 'trade_time', and create a datetime column with fallback to 'date' if 'trade_time' is missing\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m df_silver[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mdf_silver\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m \u001b[38;5;241m+\u001b[39m df_silver[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrade_time\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m00:00:00\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# sort the dataframe by date\u001b[39;00m\n\u001b[1;32m     13\u001b[0m df_silver \u001b[38;5;241m=\u001b[39m df_silver\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/arraylike.py:186\u001b[0m, in \u001b[0;36mOpsMixin.__add__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__add__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__add__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m    100\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    Get Addition of DataFrame and other, column-wise.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;124;03m    moose     3.0     NaN\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/series.py:6135\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[1;32m   6134\u001b[0m     \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_for_op(other)\n\u001b[0;32m-> 6135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexOpsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/base.py:1382\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   1379\u001b[0m     rvalues \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(rvalues\u001b[38;5;241m.\u001b[39mstart, rvalues\u001b[38;5;241m.\u001b[39mstop, rvalues\u001b[38;5;241m.\u001b[39mstep)\n\u001b[1;32m   1381\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1382\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(result, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:273\u001b[0m, in \u001b[0;36marithmetic_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# NB: We assume that extract_array and ensure_wrapped_if_datetimelike\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m#  have already been called on `left` and `right`,\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m#  and `maybe_prepare_scalar_for_op` has already been called on `right`\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# We need to special-case datetime64/timedelta64 dtypes (e.g. because numpy\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# casts integer dtypes to timedelta64 when operating with timedelta64 - GH#22390)\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    267\u001b[0m     should_extension_dispatch(left, right)\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(right, (Timedelta, BaseOffset, Timestamp))\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;66;03m# Timedelta/Timestamp and other custom scalars are included in the check\u001b[39;00m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;66;03m# because numexpr will fail on it, see GH#31457\u001b[39;00m\n\u001b[0;32m--> 273\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;66;03m# TODO we should handle EAs consistently and move this check before the if/else\u001b[39;00m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;66;03m# (https://github.com/pandas-dev/pandas/issues/41165)\u001b[39;00m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;66;03m# error: Argument 2 to \"_bool_arith_check\" has incompatible type\u001b[39;00m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[1;32m    279\u001b[0m     _bool_arith_check(op, left, right)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'DatetimeArray' and 'str'"
     ]
    }
   ],
   "source": [
    "## SILVER TO GOLD\n",
    "\n",
    "# read the csv file\n",
    "df_silver = pd.read_json(silver_file_path)\n",
    "\n",
    "# replace scrip code to compnay name\n",
    "df_silver[\"stock_name\"] = df_silver[\"scrip_code\"].replace(stock_names_dict)\n",
    "\n",
    "# combine 'date' and 'trade_time', and create a datetime column with fallback to 'date' if 'trade_time' is missing\n",
    "df_silver[\"datetime\"] = pd.to_datetime(df_silver[\"date\"] + \" \" + df_silver[\"trade_time\"].fillna(\"00:00:00\"))\n",
    "\n",
    "# sort the dataframe by date\n",
    "df_silver = df_silver.sort_values(by=\"datetime\")\n",
    "\n",
    "# rename the columns\n",
    "df_silver = df_silver.rename(\n",
    "    columns={\n",
    "        \"side\": \"trade_type\",\n",
    "        \"quantity\": \"trade_quantity\",\n",
    "        \"price\": \"trade_price\",\n",
    "    }\n",
    ")\n",
    "\n",
    "data_dict = list()\n",
    "trade_history = dict()\n",
    "for _, row in df_silver.iterrows():\n",
    "    stock_name = row[\"stock_name\"]\n",
    "\n",
    "    if stock_name not in trade_history:\n",
    "        trade_history[stock_name] = TradeHistory(stock_name)\n",
    "\n",
    "    if row[\"trade_type\"] == \"Buy\":\n",
    "        row[\"buy_price\"] = row[\"trade_price\"]\n",
    "        trade_history[stock_name].trade_price.append(row[\"trade_price\"])\n",
    "        trade_history[stock_name].trade_quantity.append(row[\"trade_quantity\"])\n",
    "    elif row[\"trade_type\"] == \"Sell\":\n",
    "        row[\"sell_price\"] = row[\"trade_price\"]\n",
    "        row[\"buy_price\"] = trade_history[stock_name].fifo_sell_calc(\n",
    "            row[\"trade_quantity\"]\n",
    "        )\n",
    "    else:\n",
    "        raise Exception(f'{row[\"trade_type\"]} was never excepected')\n",
    "    \n",
    "    row[\"holding_quantity\"] = trade_history[stock_name].holding_quantity()\n",
    "    row[\"avg_price\"] = trade_history[stock_name].calc_avg_price()\n",
    "\n",
    "    data_dict.append(row)\n",
    "\n",
    "df_gold = pd.DataFrame(data_dict)\n",
    "df_gold = df_gold.round(2)\n",
    "df_gold = df_gold[\n",
    "    [\n",
    "        \"datetime\",\n",
    "        \"stock_name\",\n",
    "        \"trade_type\",\n",
    "        \"trade_quantity\",\n",
    "        \"buy_price\",\n",
    "        \"sell_price\",\n",
    "        \"holding_quantity\",\n",
    "        \"avg_price\",\n",
    "    ]\n",
    "]\n",
    "df_gold.to_json(gold_file_path, orient=\"records\",indent=4)\n",
    "df_gold.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1387 entries, 0 to 1386\n",
      "Data columns (total 18 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   date        1387 non-null   object \n",
      " 1   BHAGERIA    1235 non-null   float64\n",
      " 2   NIFTYBEES   1235 non-null   float64\n",
      " 3   SBIN        1235 non-null   float64\n",
      " 4   PNB         1235 non-null   float64\n",
      " 5   YESBANK     1235 non-null   float64\n",
      " 6   GOLDBEES    1235 non-null   float64\n",
      " 7   KPITTECH    9 non-null      float64\n",
      " 8   IDEA        1235 non-null   float64\n",
      " 9   VOLTAS      1235 non-null   float64\n",
      " 10  TATAMOTORS  1387 non-null   float64\n",
      " 11  BPCL        1235 non-null   float64\n",
      " 12  INFY        1235 non-null   float64\n",
      " 13  TATACHEM    1235 non-null   float64\n",
      " 14  IRCTC       9 non-null      float64\n",
      " 15  HERANBA     655 non-null    float64\n",
      " 16  TATAPOWER   1387 non-null   float64\n",
      " 17  LICI        361 non-null    float64\n",
      "dtypes: float64(17), object(1)\n",
      "memory usage: 195.2+ KB\n"
     ]
    }
   ],
   "source": [
    "## GOLD STOCK_PRICE\n",
    "\n",
    "# DATA SOURCE 'https://query1.finance.yahoo.com/v7/finance/download/{each}.NS?period1=1540857600&period2=1698624000&interval=1d&events=history&includeAdjustedClose=true'\n",
    "\n",
    "# List all CSV files in the folder\n",
    "csv_files = [f for f in os.listdir(bronze_stock_price_file_path) if f.endswith(\".NS.csv\")]\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "df_gold_stock_price = None\n",
    "\n",
    "# Loop through the CSV files\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(bronze_stock_price_file_path, file)\n",
    "    stock_name = file.split(\".\")[0].upper().strip()\n",
    "    # Read the csv file\n",
    "    temp_df = pd.read_csv(file_path)\n",
    "    temp_df = temp_df[[\"Date\", \"Close\"]]\n",
    "    temp_df = temp_df.rename(\n",
    "        columns={\n",
    "            \"Date\": \"date\",\n",
    "            \"Close\": stock_name,\n",
    "        }\n",
    "    )\n",
    "    # marge the DataFrame\n",
    "    if df_gold_stock_price is not None:\n",
    "        df_gold_stock_price = pd.merge(df_gold_stock_price, temp_df, on=\"date\", how=\"outer\")\n",
    "    else:\n",
    "        df_gold_stock_price = temp_df\n",
    "\n",
    "df_gold_stock_price = df_gold_stock_price.round(2)\n",
    "\n",
    "# Save the result as a CSV file\n",
    "df_gold_stock_price.to_json(gold_stock_price_file_path, orient=\"records\",indent=4)\n",
    "df_gold_stock_price.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GOLD INVESTED and HOLDING\n",
    "\n",
    "# read the csv file\n",
    "df_gold = pd.read_json(gold_file_path)\n",
    "\n",
    "# convert Datetime to Date string\n",
    "df_gold[\"date\"] = pd.to_datetime(df_gold[\"datetime\"]).dt.date\n",
    "\n",
    "golden_table_names = {\"Invested\": \"avg_price\", \"Holdings\": \"holding_quantity\"}\n",
    "\n",
    "date_range = pd.date_range(\n",
    "    start=df_gold[\"date\"].min(), end=pd.to_datetime(\"today\"), freq=\"D\"\n",
    ")\n",
    "\n",
    "for file_name,table_name in golden_table_names.items():\n",
    "    # Create a new DataFrame with an updated date range\n",
    "    df_merged = pd.DataFrame({\"date\": date_range.date})\n",
    "    grouped = df_gold.groupby(\"stock_name\")\n",
    "    for stock_name, group in grouped:\n",
    "        df_merged = pd.merge(\n",
    "            df_merged, group[[\"date\", table_name]], on=\"date\", how=\"left\"\n",
    "        ).rename(\n",
    "            columns={table_name: stock_name},\n",
    "        )\n",
    "\n",
    "    # setting date column as index\n",
    "    df_merged.set_index(\"date\", inplace=True)\n",
    "    # Reindexing to fill the missing data with the last available data\n",
    "    df_merged = df_merged.ffill()\n",
    "    df_merged.replace(0.0, np.nan, inplace=True)\n",
    "    df_merged.to_json(f\"{gold_path}{file_name}.json\" , orient=\"records\",indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
