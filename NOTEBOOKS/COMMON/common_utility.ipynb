{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary files and packages\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from datetime import date, datetime\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "import numpy as np\n",
    "from ETLTools import DateTimeUtil\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing punctuations from the columns\n",
    "\n",
    "\n",
    "def replace_punctuation_from_string(input_str):\n",
    "    \"\"\"replace punctuation from string funcation\"\"\"\n",
    "    regex_escape_string = r\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^`{|}~\"\"\"\n",
    "    regex_remove_punctuation = re.compile(\n",
    "        \"[%s]\" % re.escape(regex_escape_string)\n",
    "    )\n",
    "    output_str = (\n",
    "        regex_remove_punctuation.sub(\"\", str(input_str))\n",
    "        .strip()\n",
    "        .replace(\" \", \"_\")\n",
    "        .replace(\"\\n\", \"_\")\n",
    "        .replace(\"\\t\", \"_\")\n",
    "        .replace(\"\\r\", \"_\")\n",
    "        .lower()\n",
    "    )\n",
    "    while \"__\" in output_str:\n",
    "        output_str = output_str.replace(\"__\", \"_\")\n",
    "    return output_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_punctuation_from_columns(df_pandas):\n",
    "    \"\"\"Pandas version of replace punctuation funcation\"\"\"\n",
    "    new_col_names = []\n",
    "    for col_name in df_pandas.columns:\n",
    "        new_col_name = replace_punctuation_from_string(col_name)\n",
    "        new_col_names.append(new_col_name)\n",
    "    df_pandas.columns = new_col_names\n",
    "    return df_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fix duplicate column names in a Pandas DataFrame\n",
    "\n",
    "\n",
    "def fix_duplicate_column_names(df_pandas):\n",
    "    \"\"\"\n",
    "    This function receives a Pandas DataFrame and ensures that each column name is unique.\n",
    "    If a duplicate name is found, the function renames it by appending an incremental number, e.g. '_1', '_2', etc.\n",
    "    The function returns a new DataFrame with the updated column names.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    counts = {}\n",
    "    for column_name in df_pandas.columns:\n",
    "        column_name = replace_punctuation_from_string(str(column_name))\n",
    "        if column_name not in counts:\n",
    "            counts[column_name] = 0\n",
    "            result.append(column_name)\n",
    "        else:\n",
    "            counts[column_name] += 1\n",
    "            result.append(f\"{column_name}_{counts[column_name]}\")\n",
    "    df_pandas.columns = result\n",
    "\n",
    "    if len(result) == 0:\n",
    "        raise ValueError(\"Duplicate column issue!\")\n",
    "    else:\n",
    "        return df_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Schema from DataContract file\n",
    "\n",
    "\n",
    "def get_schema_from_data_contract(json_path):\n",
    "    # Open and read the JSON file\n",
    "    with open(json_path, encoding=\"windows-1252\") as f:\n",
    "        # Get the contract_fields from json data\n",
    "        contract_fields = json.load(f)\n",
    "\n",
    "    # Create a list of formatted strings with field names and types\n",
    "    field_debug = [\n",
    "        f'{each[\"field_name\"]} {each[\"field_type\"]}' for each in contract_fields\n",
    "    ]\n",
    "    # Join the strings with commas and print the result\n",
    "    schema = \", \".join(field_debug)\n",
    "\n",
    "    return schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary functions to gather debug of given pandas dataframe\n",
    "\n",
    "\n",
    "def find_correct_sheetname(df_pandas, sheet_name_regex):\n",
    "    \"\"\"\n",
    "    Finds the first sheet name that matches the given regular expression.\n",
    "\n",
    "    Parameters:\n",
    "    df_pandas (dict): A dictionary where keys are sheet names and values are the corresponding data frames.\n",
    "    sheet_name_regex (str): A regular expression pattern to match against the sheet names.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: The data frame corresponding to the first sheet name that matches the regex.\n",
    "    \"\"\"\n",
    "    # Compile the regular expression for efficiency\n",
    "    pattern = re.compile(sheet_name_regex, re.IGNORECASE)\n",
    "\n",
    "    # Iterate through the sheet names\n",
    "    for sheet_name in df_pandas.keys():\n",
    "        # Check if the sheet name matches the regex pattern\n",
    "        if pattern.search(sheet_name):\n",
    "            print(f\"Sheet name => {sheet_name}\")\n",
    "            return df_pandas[sheet_name]\n",
    "\n",
    "    # Raise an error if no matching sheet name is found\n",
    "    raise ValueError(\"Sheet name not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcation to Extracts the year and month from filename\n",
    "\n",
    "\n",
    "def extract_year_month(file_name):\n",
    "    \"\"\"\n",
    "    Extracts the year and month from a given filename and returns a date object.\n",
    "\n",
    "    Parameters:\n",
    "    file_name (str): The filename from which to extract the year and month.\n",
    "\n",
    "    Returns:\n",
    "    datetime.date: The extracted date.\n",
    "    \"\"\"\n",
    "    # extracting just the base filename\n",
    "    # file_name = str(os.path.basename(file_name))\n",
    "\n",
    "    # Clean and normalize the filename string\n",
    "    file_date_str = re.sub(r\"[^A-Za-z0-9]+\", \" \", file_name).lower()\n",
    "\n",
    "    # Extract year\n",
    "    year_match = re.search(r\"20\\d{2}\", file_date_str)\n",
    "    if year_match:\n",
    "        year = year_match.group(0)\n",
    "    else:\n",
    "        raise ValueError(\"Year not found in filename\")\n",
    "\n",
    "    # Define a mapping from month abbreviations to full month names\n",
    "    month_mapping = {\n",
    "        \"jan\": \"01\",\n",
    "        \"feb\": \"02\",\n",
    "        \"mar\": \"03\",\n",
    "        \"apr\": \"04\",\n",
    "        \"may\": \"05\",\n",
    "        \"jun\": \"06\",\n",
    "        \"jul\": \"07\",\n",
    "        \"aug\": \"08\",\n",
    "        \"sep\": \"09\",\n",
    "        \"sept\": \"09\",\n",
    "        \"oct\": \"10\",\n",
    "        \"nov\": \"11\",\n",
    "        \"dec\": \"12\",\n",
    "        \"january\": \"01\",\n",
    "        \"february\": \"02\",\n",
    "        \"march\": \"03\",\n",
    "        \"april\": \"04\",\n",
    "        \"june\": \"06\",\n",
    "        \"july\": \"07\",\n",
    "        \"august\": \"08\",\n",
    "        \"september\": \"09\",\n",
    "        \"october\": \"10\",\n",
    "        \"november\": \"11\",\n",
    "        \"december\": \"12\",\n",
    "    }\n",
    "\n",
    "    # Extract month\n",
    "    month = None\n",
    "    for key, value in month_mapping.items():\n",
    "        if key in file_date_str:\n",
    "            month = value\n",
    "            break\n",
    "\n",
    "    if not month:\n",
    "        raise ValueError(\"Month not found in filename\")\n",
    "\n",
    "    # Combine year and month to form a date string and convert to date object\n",
    "    date_str = f\"{year}-{month}-01\"\n",
    "    return datetime.strptime(date_str, \"%Y-%m-%d\").date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to find data with correct header column\n",
    "\n",
    "\n",
    "def find_correct_headers(df_pandas, global_header_regex=None):\n",
    "    \"\"\"\n",
    "    Auxiliary functions to gather debug of given pandas dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    pattern = re.compile(global_header_regex, re.IGNORECASE)\n",
    "    # Iterate through the pandas data\n",
    "    for header_row_index, row in df_pandas.iterrows():\n",
    "        for each in row.values:\n",
    "            # Check if the sheet name matches the regex pattern\n",
    "            if pattern.match(replace_punctuation_from_string(str(each))):\n",
    "                df = df_pandas.iloc[header_row_index + 1 :]\n",
    "                df.columns = df_pandas.iloc[header_row_index]\n",
    "                # drop col which are all null\n",
    "                # df = df.dropna(axis=1, how=\"all\")\n",
    "                return df\n",
    "    raise ValueError(\"Header not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calc the first date of the given week and year\n",
    "# Define a Python function to compute the first date of the given week and year\n",
    "\n",
    "\n",
    "def get_first_date_of_week(year, week):\n",
    "    first_day_of_year = datetime.date(year, 1, 1)\n",
    "    if first_day_of_year.weekday() > 3:\n",
    "        first_day_of_year = first_day_of_year + datetime.timedelta(\n",
    "            7 - first_day_of_year.weekday()\n",
    "        )\n",
    "    else:\n",
    "        first_day_of_year = first_day_of_year - datetime.timedelta(\n",
    "            first_day_of_year.weekday()\n",
    "        )\n",
    "    return first_day_of_year + datetime.timedelta(weeks=week - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract year and week number\n",
    "\n",
    "\n",
    "def extract_year_week(file_path):\n",
    "    pattern = re.compile(r\"(\\d{4})week(\\d{1,2})\")\n",
    "    match = pattern.search(file_path.lower().replace(\" \", \"\"))\n",
    "    if match:\n",
    "        year, week = match.groups()\n",
    "        return int(year), int(week)\n",
    "    else:\n",
    "        raise Exception(\"Year and Week number not found in file_path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame to DataContract\n",
    "\n",
    "\n",
    "def get_correct_datatype(input_datatype):\n",
    "    input_datatype = str(input_datatype).lower().strip()\n",
    "    datatypes_list = {\n",
    "        \"Date\": [\"date\"],\n",
    "        \"String\": [\"string\", \"varchar\", \"char\", \"text\"],\n",
    "        \"Long\": [\"bigint\", \"int\", \"tinyint\", \"long\"],\n",
    "        \"Timestamp\": [\"timestamp\", \"datetime\"],\n",
    "        \"Double\": [\"double\", \"float\", \"decimal\"],\n",
    "        \"Boolean\": [\"bool\", \"boolean\"],\n",
    "    }\n",
    "    for datatype_name, datatype_values in datatypes_list.items():\n",
    "        if input_datatype in datatype_values:\n",
    "            return datatype_name\n",
    "    print(f\"undefined data type => {input_datatype}\")\n",
    "    return input_datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_contract(df):\n",
    "    # Create the list of dictionaries\n",
    "    return [\n",
    "        {\n",
    "            \"field_name\": field.name,\n",
    "            \"field_type\": get_correct_datatype(field.dataType.simpleString()),\n",
    "        }\n",
    "        for field in df.schema\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_files_availability(\n",
    "    dir_path: Union[str, Path],\n",
    "    file_pattern: str = \"*\",\n",
    "    timestamp: datetime = datetime.strptime(\"2000-01-01\", \"%Y-%m-%d\"),\n",
    ") -> List[Path]:\n",
    "    \"\"\"\n",
    "    Checks for newly added or modified files in a directory after a specific timestamp.\n",
    "\n",
    "    Args:\n",
    "        dir_path (Union[str, Path]): The directory to check for files.\n",
    "        file_pattern (str): The pattern to filter files.\n",
    "        timestamp (datetime): The timestamp to compare file modification times against.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of paths to files that were added or modified after the given timestamp.\n",
    "    \"\"\"\n",
    "    # List to store paths of matched files\n",
    "    file_paths = []\n",
    "\n",
    "    # Iterate over all files in the directory and subdirectories\n",
    "    for file_path in Path(dir_path).rglob(file_pattern):\n",
    "        if file_path.is_file():\n",
    "            file_modified_time = datetime.fromtimestamp(\n",
    "                os.path.getmtime(file_path)\n",
    "            )\n",
    "            # Check if file was modified after the given timestamp\n",
    "            if file_modified_time > timestamp:\n",
    "                file_paths.append(file_path)\n",
    "\n",
    "    # Log the number of detected files\n",
    "    num_files = len(file_paths)\n",
    "    if num_files > 0:\n",
    "        print(f\"Number of Files Detected: {num_files}\")\n",
    "        return file_paths\n",
    "    else:\n",
    "        raise FileNotFoundError(\n",
    "            f\"No processable data available in the directory: {file_path}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_with_schema(df: pd.DataFrame, schema: Dict[str, Any]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aligns the DataFrame with the given schema. Casts columns to specified data types.\n",
    "    If a column is missing, it creates that column with the specified data type and fills with NaN.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to align.\n",
    "        schema (Dict[str, Any]): A dictionary with column names as keys and data types as values.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame aligned with the provided schema.\n",
    "    \"\"\"\n",
    "    for col, dtype in schema.items():\n",
    "        if col in df.columns:\n",
    "            # Convert column to the specified data type\n",
    "            df[col] = df[col].astype(dtype)\n",
    "        else:\n",
    "            # Create column with the specified data type and fill with NaN (null)\n",
    "            df[col] = pd.Series([None] * len(df), dtype=dtype)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(\n",
    "    file_path: Union[str, Path],\n",
    "    file_pattern: str = \"*.csv\",\n",
    "    schema: Optional[Dict[str, Any]] = None,\n",
    "    timestamp: datetime = datetime.strptime(\"2000-01-01\", \"%Y-%m-%d\"),\n",
    "    sheet_name: Union[str, int] = 0,\n",
    "    header: Union[int, str] = 0,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads all files in a given directory (if `file_path` is a directory) or reads a single file.\n",
    "    Concatenates all pandas DataFrames into a single DataFrame.\n",
    "    If a schema is provided, aligns the DataFrame with the schema.\n",
    "\n",
    "    Args:\n",
    "        file_path (Union[str, Path]): Path to a file or a directory.\n",
    "        file_pattern (str): Pattern to match files in the directory (if applicable).\n",
    "        schema (Optional[Dict[str, Any]]): A dictionary with column names as keys and data types as values.\n",
    "        timestamp (datetime): Timestamp to filter files that were modified after this time.\n",
    "        sheet_name (Union[str, int]): Sheet name or index to read from Excel files.\n",
    "        header (Union[int, str]): Row number to use as column names, or string to indicate header handling.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Concatenated DataFrame of all files aligned with the schema.\n",
    "    \"\"\"\n",
    "    print(f\"Reading data from : {file_path}\")\n",
    "\n",
    "    # Initialize an empty list to store DataFrames\n",
    "    dataframes = []\n",
    "\n",
    "    # If the provided path is a directory, check for files matching the pattern and modified after the timestamp\n",
    "    if os.path.isdir(file_path):\n",
    "        files_to_read = check_files_availability(\n",
    "            file_path, file_pattern, timestamp\n",
    "        )\n",
    "    else:\n",
    "        # Otherwise, treat the provided path as a single file\n",
    "        files_to_read = [file_path]\n",
    "\n",
    "    # Iterate over each file path and read the data\n",
    "    for file in files_to_read:\n",
    "        try:\n",
    "            # Define the engine for Excel file types\n",
    "            engine = {\"xlsx\": \"openpyxl\", \"xls\": \"xlrd\", \"xlsb\": \"pyxlsb\"}\n",
    "            extension = str(file).lower().split(\".\")[-1]\n",
    "\n",
    "            # Read data based on file extension\n",
    "            if extension in engine:\n",
    "                df = pd.read_excel(\n",
    "                    file,\n",
    "                    sheet_name=sheet_name,\n",
    "                    header=header,\n",
    "                    engine=engine[extension],\n",
    "                )\n",
    "            elif extension == \"json\":\n",
    "                df = pd.read_json(file)\n",
    "            elif extension == \"csv\":\n",
    "                df = pd.read_csv(file, header=header)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported file extension: {extension}\")\n",
    "\n",
    "            # Align DataFrame with the provided schema, if schema is specified\n",
    "            if schema:\n",
    "                df = align_with_schema(df, schema)\n",
    "\n",
    "            dataframes.append(df)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "    # Concatenate all DataFrames into one\n",
    "    if dataframes:\n",
    "        combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "        return combined_df\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"No DataFrames were created; check file paths and formats.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_financial_year(date: Union[datetime, date]) -> str:\n",
    "    \"\"\"\n",
    "    Calculate the financial year for a given date.\n",
    "\n",
    "    If the month of the provided date is before April (i.e., January, February, or March),\n",
    "    the date is considered to be part of the previous financial year. Otherwise, it belongs\n",
    "    to the current financial year.\n",
    "\n",
    "    Args:\n",
    "    - date (Union[datetime, date]): The date for which to calculate the financial year.\n",
    "\n",
    "    Returns:\n",
    "    - str: The financial year in the format 'FYYYYY-YY'.\n",
    "    \"\"\"\n",
    "    # Determine the start and end years of the financial year\n",
    "    start_year = date.year - 1 if date.month < 4 else date.year\n",
    "    end_year = start_year + 1\n",
    "\n",
    "    # Format the financial year as 'FYYYYY-YY'\n",
    "    return f\"FY{start_year}-{str(end_year)[-2:]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_date_list(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Generates a list of DateTimeUtil objects representing the first day of each month\n",
    "    within the specified date range.\n",
    "\n",
    "    Args:\n",
    "        start_date (datetime.date): Start date of the range.\n",
    "        end_date (datetime.date): End date of the range.\n",
    "\n",
    "    Returns:\n",
    "        List[DateTimeUtil]: List of DateTimeUtil objects for each month within the range.\n",
    "    \"\"\"\n",
    "    month_list = []\n",
    "    current_date = min(start_date, DateTimeUtil.today())\n",
    "    end_date = min(end_date, DateTimeUtil.today())\n",
    "    while current_date <= end_date:\n",
    "        month_list.append(\n",
    "            DateTimeUtil(current_date.year, current_date.month, 1)\n",
    "        )\n",
    "        if current_date.month == 12:\n",
    "            current_date = current_date.replace(\n",
    "                year=current_date.year + 1, month=1, day=1\n",
    "            )\n",
    "        else:\n",
    "            current_date = current_date.replace(\n",
    "                month=current_date.month + 1, day=1\n",
    "            )\n",
    "    return month_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN values with empty strings in a DataFrame\n",
    "def replace_nan_with_empty(data):\n",
    "    if isinstance(data, dict):\n",
    "        return {key: replace_nan_with_empty(value) for key, value in data.items()}\n",
    "    elif isinstance(data, list):\n",
    "        return [replace_nan_with_empty(item) for item in data]\n",
    "    elif isinstance(data, float) and np.isnan(data):\n",
    "        return \"\"\n",
    "    return data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
