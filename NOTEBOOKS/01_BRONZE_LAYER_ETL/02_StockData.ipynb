{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOURCE TO BRONZE LAYER\n",
    "\n",
    "### Process:\n",
    "\n",
    "> The function fetches daily stock data using the Yahoo Finance API (`yfinance`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T01:00:34.366658Z",
     "iopub.status.busy": "2025-03-29T01:00:34.366464Z",
     "iopub.status.idle": "2025-03-29T01:00:34.819373Z",
     "shell.execute_reply": "2025-03-29T01:00:34.818796Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import json\n",
    "from datetime import timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import yfinance as yf\n",
    "from pyrate_limiter import Duration, Limiter, RequestRate\n",
    "from requests import Session\n",
    "from requests_cache import CacheMixin, SQLiteCache\n",
    "from requests_ratelimiter import LimiterMixin, MemoryQueueBucket\n",
    "\n",
    "from StockETL import DateTimeUtil, GlobalPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T01:00:34.821898Z",
     "iopub.status.busy": "2025-03-29T01:00:34.821344Z",
     "iopub.status.idle": "2025-03-29T01:00:35.007631Z",
     "shell.execute_reply": "2025-03-29T01:00:35.007023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USERNAME = 'ptprashanttripathi'\n"
     ]
    }
   ],
   "source": [
    "# Importing Common Utility Function\n",
    "%run ../COMMON/common_utility.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T01:00:35.042759Z",
     "iopub.status.busy": "2025-03-29T01:00:35.042273Z",
     "iopub.status.idle": "2025-03-29T01:00:35.046359Z",
     "shell.execute_reply": "2025-03-29T01:00:35.045922Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define Constants file paths\n",
    "stock_tickers_config_path = GlobalPath(\"CONFIG/CONSTANTS/stock_tickers.json\")\n",
    "holding_history_path = GlobalPath(f\"DATA/SOURCE/Holding/{USERNAME}/Holding_data.csv\")\n",
    "stockdata_bronze_layer_path = GlobalPath(\"DATA/BRONZE/StockData\")\n",
    "stockdata_bronze_schema_file_path = GlobalPath(\n",
    "    \"CONFIG/DATA_CONTRACTS/BRONZE/StockData.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T01:00:35.048008Z",
     "iopub.status.busy": "2025-03-29T01:00:35.047832Z",
     "iopub.status.idle": "2025-03-29T01:00:35.061429Z",
     "shell.execute_reply": "2025-03-29T01:00:35.060865Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setting cache location for yfinance\n",
    "yf.set_tz_cache_location(\".cache\")\n",
    "\n",
    "\n",
    "# Rate limiting setup\n",
    "class CachedLimiterSession(CacheMixin, LimiterMixin, Session):\n",
    "    pass\n",
    "\n",
    "\n",
    "history_rate = RequestRate(1, Duration.SECOND * 2)\n",
    "limiter = Limiter(history_rate)\n",
    "session = CachedLimiterSession(\n",
    "    limiter=limiter,\n",
    "    bucket_class=MemoryQueueBucket,\n",
    "    backend=SQLiteCache(\".cache/session\", expire_after=timedelta(hours=1)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T01:00:35.063502Z",
     "iopub.status.busy": "2025-03-29T01:00:35.063162Z",
     "iopub.status.idle": "2025-03-29T01:00:35.066847Z",
     "shell.execute_reply": "2025-03-29T01:00:35.066277Z"
    }
   },
   "outputs": [],
   "source": [
    "def download_file_from_github(output_file):\n",
    "    github_data_url = f\"https://raw.githubusercontent.com/PtPrashantTripathi/PortfolioTracker/main/DATA/BRONZE/StockData/{output_file.name}\"\n",
    "    response = requests.get(github_data_url)\n",
    "    if response.status_code == 200:\n",
    "        with open(output_file, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "    else:\n",
    "        raise Exception(\"Failed to download file from Github\")\n",
    "    print(f\"Data processed and saved to => {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T01:00:35.069210Z",
     "iopub.status.busy": "2025-03-29T01:00:35.068663Z",
     "iopub.status.idle": "2025-03-29T01:00:35.072893Z",
     "shell.execute_reply": "2025-03-29T01:00:35.072324Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_file(stock_ticker, date, output_file):\n",
    "    \"\"\"Fetch historical stock data and save it to a CSV file.\"\"\"\n",
    "    df = stock_ticker.history(\n",
    "        start=date.start_date,\n",
    "        end=min(date.end_date, DateTimeUtil.today()),\n",
    "        interval=\"1d\",\n",
    "        actions=True,\n",
    "        rounding=True,\n",
    "    )\n",
    "    if df.empty:\n",
    "        raise Exception(f\"No data fetched from {date.start_date} to {date.end_date}\")\n",
    "    df = df.reset_index()\n",
    "\n",
    "    # Replace punctuation from column names for consistency\n",
    "    df = replace_punctuation_from_columns(df)\n",
    "\n",
    "    # Fix duplicate column names by appending numerical suffixes\n",
    "    df = fix_duplicate_column_names(df)\n",
    "\n",
    "    # Drop rows where all elements are NaN\n",
    "    df = df.dropna(how=\"all\")\n",
    "\n",
    "    # Align Datafame with DataContract\n",
    "    df = align_with_datacontract(df, stockdata_bronze_schema_file_path)\n",
    "\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Data processed and saved to => {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T01:00:35.074898Z",
     "iopub.status.busy": "2025-03-29T01:00:35.074554Z",
     "iopub.status.idle": "2025-03-29T01:00:35.077865Z",
     "shell.execute_reply": "2025-03-29T01:00:35.077304Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dictionary for stock ticker overrides\n",
    "# Open and read the JSON file\n",
    "OVERWRITE_TICKERS = {}\n",
    "with open(stock_tickers_config_path, encoding=\"utf-8\") as f:\n",
    "    # Get the contract_fields from json data\n",
    "    OVERWRITE_TICKERS = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T01:00:35.079675Z",
     "iopub.status.busy": "2025-03-29T01:00:35.079352Z",
     "iopub.status.idle": "2025-03-29T01:00:35.088511Z",
     "shell.execute_reply": "2025-03-29T01:00:35.087856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from => /home/runner/work/PortfolioTracker/PortfolioTracker/DATA/SOURCE/Holding/ptprashanttripathi/Holding_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Load holding data from CSV\n",
    "df_holding_history = pd.read_csv(holding_history_path)\n",
    "df_holding_history[\"min_date\"] = pd.to_datetime(df_holding_history[\"min_date\"])\n",
    "df_holding_history[\"max_date\"] = pd.to_datetime(df_holding_history[\"max_date\"])\n",
    "print(f\"Loaded data from => {holding_history_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T01:00:35.090766Z",
     "iopub.status.busy": "2025-03-29T01:00:35.090282Z",
     "iopub.status.idle": "2025-03-29T01:00:36.622467Z",
     "shell.execute_reply": "2025-03-29T01:00:36.621866Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing data for symbol BAJAJHFL =>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed and saved to => /home/runner/work/PortfolioTracker/PortfolioTracker/DATA/BRONZE/StockData/BAJAJHFL_2025_03.csv\n",
      "\n",
      "Processing data for symbol BHAGERIA =>\n",
      "\n",
      "Processing data for symbol BPCL =>\n",
      "\n",
      "Processing data for symbol GOLDBEES =>\n",
      "\n",
      "Processing data for symbol HERANBA =>\n",
      "\n",
      "Processing data for symbol IDEA =>\n",
      "\n",
      "Processing data for symbol INFY =>\n",
      "\n",
      "Processing data for symbol IRCTC =>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed and saved to => /home/runner/work/PortfolioTracker/PortfolioTracker/DATA/BRONZE/StockData/IRCTC_2025_03.csv\n",
      "\n",
      "Processing data for symbol KPITTECH =>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed and saved to => /home/runner/work/PortfolioTracker/PortfolioTracker/DATA/BRONZE/StockData/KPITTECH_2025_03.csv\n",
      "\n",
      "Processing data for symbol LICI =>\n",
      "\n",
      "Processing data for symbol NIFTYBEES =>\n",
      "\n",
      "Processing data for symbol PNB =>\n",
      "\n",
      "Processing data for symbol SBIN =>\n",
      "\n",
      "Processing data for symbol TATACHEM =>\n",
      "\n",
      "Processing data for symbol TATAMOTORS =>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed and saved to => /home/runner/work/PortfolioTracker/PortfolioTracker/DATA/BRONZE/StockData/TATAMOTORS_2025_03.csv\n",
      "\n",
      "Processing data for symbol TATAPOWER =>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed and saved to => /home/runner/work/PortfolioTracker/PortfolioTracker/DATA/BRONZE/StockData/TATAPOWER_2025_03.csv\n",
      "\n",
      "Processing data for symbol UNITDSPR =>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed and saved to => /home/runner/work/PortfolioTracker/PortfolioTracker/DATA/BRONZE/StockData/UNITDSPR_2025_03.csv\n",
      "\n",
      "Processing data for symbol VOLTAS =>\n",
      "\n",
      "Processing data for symbol YESBANK =>\n",
      "\n",
      "Processing data for symbol MIRAE_ASSET_ELSS_TAX_SAVER_FUND_DIRECT_PLAN_GROWTH =>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed and saved to => /home/runner/work/PortfolioTracker/PortfolioTracker/DATA/BRONZE/StockData/MIRAE_ASSET_ELSS_TAX_SAVER_FUND_DIRECT_PLAN_GROWTH_2025_03.csv\n",
      "\n",
      "Processing data for symbol SBI_LONG_TERM_EQUITY_FUND_DIRECT_PLAN_GROWTH =>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed and saved to => /home/runner/work/PortfolioTracker/PortfolioTracker/DATA/BRONZE/StockData/SBI_LONG_TERM_EQUITY_FUND_DIRECT_PLAN_GROWTH_2025_03.csv\n"
     ]
    }
   ],
   "source": [
    "# Fetch stock data and process it.\n",
    "for _, row in df_holding_history.iterrows():\n",
    "    print(f\"\\nProcessing data for symbol {row['symbol']} =>\")\n",
    "    try:\n",
    "        stock_ticker = yf.Ticker(\n",
    "            OVERWRITE_TICKERS.get(row[\"symbol\"], row[\"isin\"]),\n",
    "            session=session,\n",
    "        )\n",
    "        date_list = generate_date_list(\n",
    "            row[\"min_date\"].to_pydatetime(), row[\"max_date\"].to_pydatetime()\n",
    "        )\n",
    "        for date in date_list:\n",
    "            output_file = stockdata_bronze_layer_path.joinpath(\n",
    "                f\"{row['symbol']}_{date.year:04d}_{date.month:02d}.csv\"\n",
    "            )\n",
    "            if (\n",
    "                output_file.exists()\n",
    "                and date.month_difference(DateTimeUtil.today()) >= 1\n",
    "            ):\n",
    "                continue\n",
    "            else:\n",
    "                try:\n",
    "                    download_file_from_github(output_file)\n",
    "                except:\n",
    "                    process_file(stock_ticker, date, output_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {row['symbol']} =>\\n{e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_debug": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
