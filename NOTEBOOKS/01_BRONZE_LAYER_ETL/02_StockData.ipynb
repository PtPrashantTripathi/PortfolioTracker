{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOURCE TO BRONZE LAYER\n",
    "\n",
    "### Process:\n",
    "\n",
    "> The function fetches daily stock data using the Yahoo Finance API (`yfinance`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T21:19:31.186858Z",
     "iopub.status.busy": "2024-09-20T21:19:31.186663Z",
     "iopub.status.idle": "2024-09-20T21:19:31.666993Z",
     "shell.execute_reply": "2024-09-20T21:19:31.666313Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from datetime import  timedelta\n",
    "import yfinance as yf\n",
    "from requests import Session\n",
    "from pyrate_limiter import Limiter, Duration, RequestRate\n",
    "from requests_cache import CacheMixin, SQLiteCache\n",
    "from requests_ratelimiter import LimiterMixin, MemoryQueueBucket\n",
    "from ETLTools import DateTimeUtil, GlobalPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T21:19:31.669308Z",
     "iopub.status.busy": "2024-09-20T21:19:31.669051Z",
     "iopub.status.idle": "2024-09-20T21:19:31.803396Z",
     "shell.execute_reply": "2024-09-20T21:19:31.802710Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing Common Utility Funcation\n",
    "%run ../COMMON/common_utility.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_dict = {\n",
    "    \"DEEPAKNTR\": \"DEEPAKNTR.BO\",\n",
    "    \"GITARENEW\": \"GITARENEW.BO\",\n",
    "    \"KPEL\": \"KPEL.BO\",\n",
    "    \"RAGHUSYN\": \"RAGHUSYN.BO\",\n",
    "    \"SWORDEDGE\": \"SWORDEDGE.BO\",\n",
    "    \"URJA\": \"URJA.BO\",\n",
    "    \"VIJIFIN\": \"VIJIFIN.NS\",\n",
    "    \"VIRTUALG\": \"VIRTUALG.BO\",\n",
    "    \"CTL\": \"CTL.BO\",\n",
    "    \"VIRTUALG\": \"VIRTUALG.BO\",\n",
    "    \"LLOYDSENGG\": \"LLOYDSENGG.BO\",\n",
    "    \"CRESSAN\": \"CRESSAN.BO\",\n",
    "    \"YAMNINV\": \"YAMNINV.BO\",\n",
    "    \"VIRTUALG\": \"VIRTUALG.BO\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T21:19:31.805298Z",
     "iopub.status.busy": "2024-09-20T21:19:31.805122Z",
     "iopub.status.idle": "2024-09-20T21:19:31.808406Z",
     "shell.execute_reply": "2024-09-20T21:19:31.807990Z"
    }
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "# Define Constants file paths\n",
    "HOLDINGS_HISTORY_PATH = GlobalPath(\"DATA/SOURCE/Holdings/HoldingsHistory_data.csv\")\n",
    "STOCKDATA_BRONZE_LAYER_PATH = GlobalPath(\"DATA/BRONZE/StockData\")"
=======
    "def process_file(\n",
    "    isin: str, symbol: str, date_obj: DateTimeUtil, output_file: GlobalPath\n",
    "):\n",
    "    \"\"\"\n",
    "    Processes historical stock data for a given symbol and saves it to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        isin (str): The ISIN code of the stock.\n",
    "        symbol (str): The symbol of the stock.\n",
    "        date_obj (DateTimeUtil): DateTimeUtil object representing the date.\n",
    "        output_file (str): Path to the output CSV file where the processed data will be saved.\n",
    "    \"\"\"\n",
    "    # Log the start of processing for the given symbol\n",
    "    print(\n",
    "        f\"\\nStarting data processing for:\\nsymbol: {symbol}\\nyear: {date_obj.year}\\nmonth : {date_obj.month}\\n\"\n",
    "    )\n",
    "\n",
    "    # Fetch historical data from Yahoo Finance for the specified date range\n",
    "    stock = yf.Ticker(symbol_dict.get(symbol, isin))\n",
    "    df = stock.history(\n",
    "        start=date_obj.start_date,\n",
    "        end=min(date_obj.end_date, DateTimeUtil.today()),\n",
    "        interval=\"1d\",\n",
    "    )\n",
    "\n",
    "    # Check if the DataFrame is empty and raise an exception if no data is fetched\n",
    "    if df.empty:\n",
    "        raise Exception(\n",
    "            f\"No data fetched for {symbol} from {date_obj.start_date} to {date_obj.end_date}\"\n",
    "        )\n",
    "\n",
    "    # Reset the index to ensure date is a column\n",
    "    df = df.reset_index()\n",
    "\n",
    "    # Replace punctuation in column names for consistency\n",
    "    df = utils.replace_punctuation_from_columns(df)\n",
    "\n",
    "    # Fix duplicate column names by appending numerical suffixes\n",
    "    df = utils.fix_duplicate_column_names(df)\n",
    "\n",
    "    # Round numerical values to 2 decimal places\n",
    "    df = df.round(2)\n",
    "\n",
    "    # Save the processed DataFrame to a CSV file\n",
    "    df.to_csv(output_file, index=False)\n",
    "\n",
    "    # Log successful processing and saving of data\n",
    "    print(f\"Data processed and saved to: {output_file}\")"
>>>>>>> main
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T21:19:31.810174Z",
     "iopub.status.busy": "2024-09-20T21:19:31.809833Z",
     "iopub.status.idle": "2024-09-20T21:19:31.820999Z",
     "shell.execute_reply": "2024-09-20T21:19:31.820414Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setting cache location for yfinance\n",
    "yf.set_tz_cache_location(\".cache\")\n",
    "\n",
    "# Rate limiting setup\n",
    "class CachedLimiterSession(CacheMixin, LimiterMixin, Session):\n",
    "    pass\n",
    "\n",
    "history_rate = RequestRate(1, Duration.SECOND * 2)\n",
    "limiter = Limiter(history_rate)\n",
    "session = CachedLimiterSession(\n",
    "    limiter=limiter,\n",
    "    bucket_class=MemoryQueueBucket,\n",
    "    backend=SQLiteCache(\".cache/session\", expire_after=timedelta(hours=1)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T21:19:31.822839Z",
     "iopub.status.busy": "2024-09-20T21:19:31.822561Z",
     "iopub.status.idle": "2024-09-20T21:19:31.826330Z",
     "shell.execute_reply": "2024-09-20T21:19:31.825743Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_file(stock_ticker, date, output_file):\n",
    "    \"\"\"Fetch historical stock data and save it to a CSV file.\"\"\"\n",
    "    df = stock_ticker.history(\n",
    "        start=date.start_date,\n",
    "        end=min(date.end_date, DateTimeUtil.today()),\n",
    "        interval=\"1d\",\n",
    "        actions=True,\n",
    "        rounding=True,\n",
    "    )\n",
    "    if df.empty:\n",
    "        raise Exception(f\"No data fetched for : from {date.start_date} to {date.end_date}\")\n",
    "    df = df.reset_index()\n",
    "    df = replace_punctuation_from_columns(df)\n",
    "    df = fix_duplicate_column_names(df)\n",
    "    df = df.round(2)\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Data processed and saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T21:19:31.828007Z",
     "iopub.status.busy": "2024-09-20T21:19:31.827820Z",
     "iopub.status.idle": "2024-09-20T21:19:31.831278Z",
     "shell.execute_reply": "2024-09-20T21:19:31.830795Z"
    }
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "# Dictionary for stock ticker overrides\n",
    "OVERWRITE_TICKERS = {\n",
    "    \"BAJAJHFL\":\"BAJAJHFL.NS\",\n",
    "    \"BHAGERIA\": \"BHAGERIA.NS\",\n",
    "    \"BPCL\": \"BPCL.NS\",\n",
    "    \"GOLDBEES\": \"GOLDBEES.NS\",\n",
    "    \"HERANBA\": \"HERANBA.NS\",\n",
    "    \"IDEA\": \"IDEA.NS\",\n",
    "    \"INFY\": \"INFY.NS\",\n",
    "    \"IRCTC\": \"IRCTC.NS\",\n",
    "    \"KPITTECH\": \"KPITTECH.NS\",\n",
    "    \"LICI\": \"LICI.NS\",\n",
    "    \"MIRAE_ASSET_ELSS_TAX_SAVER_FUND_DIRECT_PLAN_GROWTH\": \"0P00017844.BO\",\n",
    "    \"NIFTYBEES\": \"NIFTYBEES.NS\",\n",
    "    \"PNB\": \"PNB.NS\",\n",
    "    \"SBIN\": \"SBIN.NS\",\n",
    "    \"SBI_LONG_TERM_EQUITY_FUND_DIRECT_PLAN_GROWTH\": \"0P0000XVL9.BO\",\n",
    "    \"TATACHEM\": \"TATACHEM.NS\",\n",
    "    \"TATAMOTORS\": \"TATAMOTORS.NS\",\n",
    "    \"TATAPOWER\": \"TATAPOWER.NS\",\n",
    "    \"VOLTAS\": \"VOLTAS.NS\",\n",
    "    \"YESBANK\": \"YESBANK.NS\",\n",
    "}"
=======
    "error = {}\n",
    "# Iterate over each stock holding record\n",
    "for _, row in df_holdingshistory.iterrows():\n",
    "    # Generate a list of months within the date range for each stock\n",
    "    date_list = generate_date_list(\n",
    "        row[\"min_date\"].to_pydatetime(), row[\"max_date\"].to_pydatetime()\n",
    "    )\n",
    "    for each in date_list:\n",
    "        try:\n",
    "            # Determine the output file path in the bronze layer\n",
    "            output_file = stockdata_bronze_layer_path.joinpath(\n",
    "                f\"{row['symbol']}_{each.year:04d}_{each.month:02d}.csv\"\n",
    "            )\n",
    "            # Check if the file exists and skip if it's older than 2 months\n",
    "            if output_file.exists():\n",
    "                month_difference = each.month_difference(DateTimeUtil.today())\n",
    "                if month_difference > 0:\n",
    "                    continue\n",
    "\n",
    "            # Process and save the file\n",
    "            process_file(\n",
    "                isin=row[\"isin\"],\n",
    "                symbol=row[\"symbol\"],\n",
    "                date_obj=each,\n",
    "                output_file=output_file,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            # Log any errors encountered during processing\n",
    "            print(\n",
    "                f\"Error processing data for symbol {row['symbol']} with error:\\n{e}\"\n",
    "            )\n",
    "            if row[\"symbol\"] not in error:\n",
    "                error[row[\"symbol\"]] = {row[\"isin\"]: []}\n",
    "            error[row[\"symbol\"]][row[\"isin\"]].append(each)"
>>>>>>> main
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T21:19:31.833096Z",
     "iopub.status.busy": "2024-09-20T21:19:31.832738Z",
     "iopub.status.idle": "2024-09-20T21:19:31.840897Z",
     "shell.execute_reply": "2024-09-20T21:19:31.840332Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from: /home/runner/work/PortfolioTracker/PortfolioTracker/DATA/SOURCE/Holdings/HoldingsHistory_data.csv\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "# Load holdings data from CSV\n",
    "df_holdings_history = pd.read_csv(HOLDINGS_HISTORY_PATH)\n",
    "df_holdings_history[\"min_date\"] = pd.to_datetime(df_holdings_history[\"min_date\"])\n",
    "df_holdings_history[\"max_date\"] = pd.to_datetime(df_holdings_history[\"max_date\"])\n",
    "print(f\"Loaded data from: {HOLDINGS_HISTORY_PATH}\")"
=======
    "# import pandas as pd\n",
    "\n",
    "# # Read the CSV file\n",
    "# df = pd.read_csv(\"C:/Users/Harshal Khandalkar/Downloads/VIRTUALG.csv\")\n",
    "\n",
    "# # Rename columns to match the desired format\n",
    "# df.columns = [\n",
    "#     \"date\",\n",
    "#     \"close\",\n",
    "#     \"open\",\n",
    "#     \"high\",\n",
    "#     \"low\",\n",
    "#     \"volume\",\n",
    "#     \"Change\",\n",
    "# ]\n",
    "\n",
    "# # Select and rename columns as per the desired output\n",
    "# df = df[[\"date\", \"open\", \"high\", \"low\", \"close\", \"volume\"]]\n",
    "\n",
    "# # Convert 'Date' column to datetime format and adjust timezone\n",
    "# df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%d-%m-%Y\")\n",
    "# # One-liner to generate the 'output_file' column\n",
    "# df[\"output_file\"] = df.apply(\n",
    "#     lambda row: f\"VIRTUALG_{row.date.year:04d}_{row.date.month:02d}.csv\", axis=1\n",
    "# )\n",
    "# df[\"date\"] = df[\"date\"].dt.strftime(\"%Y-%m-%d\") + \" 00:00:00+05:30\"\n",
    "\n",
    "\n",
    "# # Function to convert the string with suffix to a float\n",
    "# def convert_to_float(s):\n",
    "#     s = (\n",
    "#         str(s).strip().upper()\n",
    "#     )  # Ensure consistent casing and remove extra spaces\n",
    "#     if s.endswith(\"M\"):\n",
    "#         return float(s[:-1]) * 1_000_000\n",
    "#     elif s.endswith(\"K\"):\n",
    "#         return float(s[:-1]) * 1_000\n",
    "#     elif s.endswith(\"B\"):\n",
    "#         return float(s[:-1]) * 1_000_000_000\n",
    "#     else:\n",
    "#         return float(s)  # Handle cases without suffix\n",
    "\n",
    "\n",
    "# # Apply the conversion function to the column\n",
    "# df[\"volume\"] = 0.0\n",
    "\n",
    "# # Add placeholder columns for dividends and stock_splits\n",
    "# df[\"dividends\"] = 0.0\n",
    "# df[\"stock_splits\"] = 0.0\n",
    "\n",
    "# for output_file, grp in df.groupby(\"output_file\"):\n",
    "#     output_file = stockdata_bronze_layer_path.joinpath(output_file)\n",
    "#     GlobalPath.ensure_exists(\n",
    "#         output_file\n",
    "#     )  # Create directories if they don't exist\n",
    "#     grp[\n",
    "#         [\n",
    "#             \"date\",\n",
    "#             \"open\",\n",
    "#             \"high\",\n",
    "#             \"low\",\n",
    "#             \"close\",\n",
    "#             \"volume\",\n",
    "#             \"dividends\",\n",
    "#             \"stock_splits\",\n",
    "#         ]\n",
    "#     ].to_csv(output_file, index=False)\n",
    "#     print(output_file)"
>>>>>>> main
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-20T21:19:31.878175Z",
     "iopub.status.busy": "2024-09-20T21:19:31.877680Z",
     "iopub.status.idle": "2024-09-20T21:19:58.126740Z",
     "shell.execute_reply": "2024-09-20T21:19:58.126141Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing data for symbol BAJAJHFL:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BAJAJHFL.NS: Period '1mo' is invalid, must be one of ['1d', '5d', 'ytd', 'max']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing BAJAJHFL:\n",
      "No data fetched for : from 2024-09-01 00:00:00 to 2024-09-30 00:00:00\n",
      "\n",
      "Processing data for symbol BHAGERIA:\n",
      "\n",
      "Processing data for symbol BPCL:\n",
      "\n",
      "Processing data for symbol GOLDBEES:\n",
      "\n",
      "Processing data for symbol HERANBA:\n",
      "\n",
      "Processing data for symbol IDEA:\n",
      "\n",
      "Processing data for symbol INFY:\n",
      "\n",
      "Processing data for symbol IRCTC:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed and saved to: /home/runner/work/PortfolioTracker/PortfolioTracker/DATA/BRONZE/StockData/IRCTC_2024_09.csv\n",
      "\n",
      "Processing data for symbol KPITTECH:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed and saved to: /home/runner/work/PortfolioTracker/PortfolioTracker/DATA/BRONZE/StockData/KPITTECH_2024_09.csv\n",
      "\n",
      "Processing data for symbol LICI:\n",
      "\n",
      "Processing data for symbol NIFTYBEES:\n",
      "\n",
      "Processing data for symbol PNB:\n",
      "\n",
      "Processing data for symbol SBIN:\n",
      "\n",
      "Processing data for symbol TATACHEM:\n",
      "\n",
      "Processing data for symbol TATAMOTORS:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed and saved to: /home/runner/work/PortfolioTracker/PortfolioTracker/DATA/BRONZE/StockData/TATAMOTORS_2024_09.csv\n",
      "\n",
      "Processing data for symbol TATAPOWER:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed and saved to: /home/runner/work/PortfolioTracker/PortfolioTracker/DATA/BRONZE/StockData/TATAPOWER_2024_09.csv\n",
      "\n",
      "Processing data for symbol VOLTAS:\n",
      "\n",
      "Processing data for symbol YESBANK:\n",
      "\n",
      "Processing data for symbol MIRAE_ASSET_ELSS_TAX_SAVER_FUND_DIRECT_PLAN_GROWTH:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed and saved to: /home/runner/work/PortfolioTracker/PortfolioTracker/DATA/BRONZE/StockData/MIRAE_ASSET_ELSS_TAX_SAVER_FUND_DIRECT_PLAN_GROWTH_2024_09.csv\n",
      "\n",
      "Processing data for symbol SBI_LONG_TERM_EQUITY_FUND_DIRECT_PLAN_GROWTH:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed and saved to: /home/runner/work/PortfolioTracker/PortfolioTracker/DATA/BRONZE/StockData/SBI_LONG_TERM_EQUITY_FUND_DIRECT_PLAN_GROWTH_2024_09.csv\n"
     ]
    }
   ],
   "source": [
    "# Fetch stock data and process it.\n",
    "for _, row in df_holdings_history.iterrows():\n",
    "  print(f\"\\nProcessing data for symbol {row['symbol']}:\")\n",
    "  try:\n",
    "    stock_ticker = yf.Ticker(\n",
    "        OVERWRITE_TICKERS.get(row[\"symbol\"], row[\"isin\"]),\n",
    "        session=session,\n",
    "    )\n",
    "    date_list = generate_date_list(row[\"min_date\"].to_pydatetime(), row[\"max_date\"].to_pydatetime())   \n",
    "    for date in date_list:\n",
    "        output_file = STOCKDATA_BRONZE_LAYER_PATH.joinpath(f\"{row['symbol']}_{date.year:04d}_{date.month:02d}.csv\")\n",
    "        if output_file.exists() and date.month_difference(DateTimeUtil.today()) >= 1:\n",
    "            continue\n",
    "        process_file(stock_ticker, date, output_file)\n",
    "  except Exception as e:\n",
    "    print(f\"Error processing {row['symbol']}:\\n{e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_debug": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
