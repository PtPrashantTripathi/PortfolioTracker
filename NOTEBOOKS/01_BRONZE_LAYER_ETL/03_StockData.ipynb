{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOURCE TO BRONZE LAYER\n",
    "\n",
    "### Process:\n",
    "\n",
    "> The function fetches daily stock data using the Yahoo Finance API (`yfinance`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import yfinance as yf\n",
    "\n",
    "from StockETL.datetimeutils import DateTimeUtil\n",
    "from StockETL.globalpath import GlobalPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Common Utility Function\n",
    "%run ../COMMON/common_utility.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "stock_tickers_config_path = GlobalPath(\"DATA/CONFIG/CONSTANTS/stock_tickers.json\")\n",
    "holding_history_path = GlobalPath(\"DATA/SOURCE/Holding\")\n",
    "stockdata_bronze_schema_file_path = GlobalPath(\n",
    "    \"DATA/CONFIG/DATA_CONTRACTS/BRONZE/StockData.json\"\n",
    ")\n",
    "failed_records_path = GlobalPath(\"DATA/FAILED/failed_records.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for stock ticker overrides\n",
    "# Open and read the JSON file\n",
    "OVERWRITE_TICKERS = {}\n",
    "with open(stock_tickers_config_path, encoding=\"utf-8\") as f:\n",
    "    # Get the contract_fields from json data\n",
    "    OVERWRITE_TICKERS = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_date_list(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Generates a list of DateTimeUtil objects representing the first day of each month\n",
    "    within the specified date range.\n",
    "\n",
    "    Args:\n",
    "        start_date (datetime.date): Start date of the range.\n",
    "        end_date (datetime.date): End date of the range.\n",
    "\n",
    "    Returns:\n",
    "        List[DateTimeUtil]: List of DateTimeUtil objects for each month within the range.\n",
    "    \"\"\"\n",
    "    month_list = []\n",
    "    current_date = min(start_date, DateTimeUtil.today())\n",
    "    end_date = min(end_date, DateTimeUtil.today())\n",
    "    while current_date <= end_date:\n",
    "        month_list.append(DateTimeUtil(current_date.year, current_date.month, 1))\n",
    "        if current_date.month == 12:\n",
    "            current_date = current_date.replace(\n",
    "                year=current_date.year + 1, month=1, day=1\n",
    "            )\n",
    "        else:\n",
    "            current_date = current_date.replace(month=current_date.month + 1, day=1)\n",
    "    return month_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file_from_github(output_file):\n",
    "    github_data_url = f\"https://raw.githubusercontent.com/PtPrashantTripathi/PortfolioTracker/main/DATA/BRONZE/StockData/{output_file.name}\"\n",
    "    response = requests.get(github_data_url)\n",
    "    if response.status_code == 200:\n",
    "        with open(output_file, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "            return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download data\n",
    "\n",
    "\n",
    "def process_stock_data(row: dict):\n",
    "    all_status = []\n",
    "    try:\n",
    "        stock_ticker = yf.Ticker(OVERWRITE_TICKERS.get(row[\"symbol\"], row[\"isin\"]))\n",
    "        stockdata_bronze_layer_path = GlobalPath(\n",
    "            f\"DATA/BRONZE/StockData/{row[\"symbol\"]}\"\n",
    "        )\n",
    "        date_list = generate_date_list(\n",
    "            row[\"min_date\"].to_pydatetime(), row[\"max_date\"].to_pydatetime()\n",
    "        )\n",
    "        for date in date_list:\n",
    "            status, info = None, None\n",
    "            output_file = stockdata_bronze_layer_path.joinpath(\n",
    "                f\"{row['symbol']}_{date.year:04d}_{date.month:02d}.csv\"\n",
    "            )\n",
    "\n",
    "            if (\n",
    "                output_file.exists()\n",
    "                and date.month_difference(DateTimeUtil.today()) >= 1\n",
    "            ):\n",
    "                status = \"exists\"\n",
    "            elif download_file_from_github(output_file):\n",
    "                status = \"downloaded\"\n",
    "                info = \"github\"\n",
    "            else:\n",
    "                try:\n",
    "                    df = stock_ticker.history(\n",
    "                        start=date.start_date,\n",
    "                        end=min(date.end_date, DateTimeUtil.today()),\n",
    "                        interval=\"1d\",\n",
    "                        actions=True,\n",
    "                        rounding=True,\n",
    "                    )\n",
    "\n",
    "                    if df.empty:\n",
    "                        raise ValueError(\"No data returned\")\n",
    "\n",
    "                    df = df.reset_index()\n",
    "\n",
    "                    # Replace punctuation from column names for consistency\n",
    "                    df = replace_punctuation_from_columns(df)\n",
    "\n",
    "                    # Fix duplicate column names by appending numerical suffixes\n",
    "                    df = fix_duplicate_column_names(df)\n",
    "\n",
    "                    # Drop rows where all elements are NaN\n",
    "                    df = df.dropna(how=\"all\")\n",
    "\n",
    "                    # Align Datafame with DataContract\n",
    "                    df = align_with_datacontract(df, stockdata_bronze_schema_file_path)\n",
    "\n",
    "                    df.to_csv(output_file, index=False)\n",
    "                    status = \"downloaded\"\n",
    "                    info = \"yfinance\"\n",
    "                except Exception as e:\n",
    "                    status = \"failed\"\n",
    "                    info = str(e)\n",
    "            all_status.append(\n",
    "                {\n",
    "                    \"symbol\": row[\"symbol\"],\n",
    "                    \"start_date\": date.start_date,\n",
    "                    \"end_date\": date.end_date,\n",
    "                    \"status\": status,\n",
    "                    \"info\": info,\n",
    "                    \"file\": GlobalPath.relative(output_file),\n",
    "                }\n",
    "            )\n",
    "    except Exception as e:\n",
    "        all_status.append(\n",
    "            {\n",
    "                \"symbol\": row[\"symbol\"],\n",
    "                \"start_date\": row[\"min_date\"].to_pydatetime(),\n",
    "                \"end_date\": row[\"max_date\"].to_pydatetime(),\n",
    "                \"status\": \"failed\",\n",
    "                \"error\": str(e),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return all_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate file paths for available Excel files in the source layer\n",
    "file_paths = check_files_availability(\n",
    "    holding_history_path, file_pattern=\"Holding_data.csv\"\n",
    ")\n",
    "\n",
    "# Load holding history\n",
    "df_holding_history = pd.concat([pd.read_csv(file_path) for file_path in file_paths])\n",
    "df_holding_history[\"min_date\"] = pd.to_datetime(df_holding_history[\"min_date\"])\n",
    "df_holding_history[\"max_date\"] = pd.to_datetime(df_holding_history[\"max_date\"])\n",
    "\n",
    "# Calculate the min and max dates for each stock\n",
    "df_holding_history = (\n",
    "    df_holding_history.groupby([\"segment\", \"exchange\", \"symbol\"])\n",
    "    .agg(\n",
    "        min_date=(\"min_date\", \"min\"),\n",
    "        max_date=(\"max_date\", \"max\"),\n",
    "        isin=(\"isin\", \"first\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# os.environ[\"SSL_CERT_DIR\"] = \"/opt/homebrew/etc/ca-certificates\"\n",
    "# os.environ[\"SSL_CERT_FILE\"] = \"/opt/homebrew/etc/ca-certificates/cert.pem\"\n",
    "# os.environ[\"REQUESTS_CA_BUNDLE\"] = \"/opt/homebrew/etc/ca-certificates/cert.pem\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process in parallel\n",
    "all_status = []\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    results = executor.map(\n",
    "        process_stock_data, df_holding_history.to_dict(orient=\"records\")\n",
    "    )\n",
    "    for result in results:\n",
    "        all_status.extend(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save failed records\n",
    "df = pd.DataFrame(all_status)\n",
    "df[~df[\"status\"].isin([\"exists\", \"downloaded\"])]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_debug": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
