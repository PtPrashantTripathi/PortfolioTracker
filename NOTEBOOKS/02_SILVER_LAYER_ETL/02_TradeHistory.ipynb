{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BRONZE TO SILVER LAYER\n",
    "\n",
    "### Reading & Validate the Data from the Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T01:00:15.119330Z",
     "iopub.status.busy": "2025-04-19T01:00:15.118859Z",
     "iopub.status.idle": "2025-04-19T01:00:15.356510Z",
     "shell.execute_reply": "2025-04-19T01:00:15.355991Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing Common Utility Function\n",
    "import pandas as pd\n",
    "\n",
    "from StockETL import GlobalPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T01:00:15.358896Z",
     "iopub.status.busy": "2025-04-19T01:00:15.358365Z",
     "iopub.status.idle": "2025-04-19T01:00:15.512951Z",
     "shell.execute_reply": "2025-04-19T01:00:15.512342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USERNAME = 'ptprashanttripathi'\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries and utility functions\n",
    "%run ../COMMON/common_utility.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T01:00:15.547886Z",
     "iopub.status.busy": "2025-04-19T01:00:15.547491Z",
     "iopub.status.idle": "2025-04-19T01:00:15.551673Z",
     "shell.execute_reply": "2025-04-19T01:00:15.551263Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate GlobalPath\n",
    "tradehistory_bronze_layer_path = GlobalPath(\"DATA/BRONZE/TradeHistory\")\n",
    "symbol_silver_file_path = GlobalPath(\"DATA/SILVER/Symbol/Symbol_data.csv\")\n",
    "tradehistory_silver_file_path = GlobalPath(\n",
    "    f\"DATA/SILVER/TradeHistory/{USERNAME}/TradeHistory_data.csv\"\n",
    ")\n",
    "tradehistory_silver_schema_file_path = GlobalPath(\n",
    "    \"CONFIG/DATA_CONTRACTS/SILVER/TradeHistory.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Definitions\n",
    "\n",
    "- **concat_company**: Concatenates stock names based on instrument type.\n",
    "- **read_file**: Reads and processes a CSV file from the Bronze layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T01:00:15.553652Z",
     "iopub.status.busy": "2025-04-19T01:00:15.553311Z",
     "iopub.status.idle": "2025-04-19T01:00:15.556800Z",
     "shell.execute_reply": "2025-04-19T01:00:15.556373Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to apply the conditional concatenation\n",
    "\n",
    "\n",
    "def get_scrip_name(row: pd.Series) -> str:\n",
    "    \"\"\"\n",
    "    Concatenate stock names based on the instrument type.\n",
    "\n",
    "    Parameters:\n",
    "    row (pd.Series): A row of DataFrame containing instrument data.\n",
    "\n",
    "    Returns:\n",
    "    str: The concatenated stock name.\n",
    "    \"\"\"\n",
    "    if row[\"instrument_type\"] == \"European Call\":\n",
    "        company = (\n",
    "            str(row[\"company\"])\n",
    "            + \"-CE-\"\n",
    "            + str(row[\"strike_price\"])\n",
    "            + \"-\"\n",
    "            + row[\"expiry\"]\n",
    "        )\n",
    "    elif row[\"instrument_type\"] == \"European Put\":\n",
    "        company = (\n",
    "            str(row[\"company\"])\n",
    "            + \"-PE-\"\n",
    "            + str(row[\"strike_price\"])\n",
    "            + \"-\"\n",
    "            + row[\"expiry\"]\n",
    "        )\n",
    "    else:\n",
    "        company = str(row[\"company\"])\n",
    "    return company.strip().upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T01:00:15.558592Z",
     "iopub.status.busy": "2025-04-19T01:00:15.558249Z",
     "iopub.status.idle": "2025-04-19T01:00:15.563212Z",
     "shell.execute_reply": "2025-04-19T01:00:15.562738Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to read and process a CSV file\n",
    "\n",
    "\n",
    "def read_file(file_path: GlobalPath):\n",
    "    \"\"\"\n",
    "    Reads and processes a CSV file from the Bronze layer.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The processed DataFrame.\n",
    "    \"\"\"\n",
    "    print(f\"Processing file => {file_path}\")\n",
    "\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = replace_punctuation_from_columns(df)\n",
    "\n",
    "    # Convert 'trade_num' to int\n",
    "    df[\"trade_num\"] = df[\"trade_num\"].fillna(0).astype(int)\n",
    "\n",
    "    # Add Datetime Col\n",
    "    df[\"datetime\"] = pd.to_datetime(\n",
    "        df[\"date\"].str.replace(\"00:00:00\", \"\").str.strip()\n",
    "        + \" \"\n",
    "        + df[\"trade_time\"]\n",
    "        .fillna(\"00:00:00\")\n",
    "        .apply(lambda x: x if len(x.split(\":\")) == 3 else x + \":00\"),\n",
    "        format=\"%Y-%m-%d %H:%M:%S\",\n",
    "    )\n",
    "\n",
    "    # Convert 'expiry' to desired string format\n",
    "    df[\"expiry_date\"] = pd.to_datetime(df[\"expiry\"], format=\"%d-%m-%Y\")\n",
    "    df[\"expiry\"] = df[\"expiry_date\"].dt.strftime(\"%d%b%Y\")\n",
    "    df[\"expiry_date\"] = df[\"expiry_date\"].dt.strftime(\"%Y-%m-%d\").fillna(\"\")\n",
    "\n",
    "    # Convert the 'side' column in df to uppercase\n",
    "    df[\"side\"] = df[\"side\"].astype(str).str.strip().str.upper()\n",
    "\n",
    "    # Add the \"IN\" prefix to 'scrip_code'\n",
    "    df[\"scrip_code\"] = \"IN\" + df[\"scrip_code\"].astype(str).str.strip().str.upper()\n",
    "\n",
    "    # Apply the function to the DataFrame\n",
    "    df[\"scrip_name\"] = df.apply(get_scrip_name, axis=1)\n",
    "\n",
    "    # Calc amount\n",
    "    df[\"amount\"] = df[\"price\"] * df[\"quantity\"]\n",
    "\n",
    "    # Remove all-NA columns from each DataFrame\n",
    "    df = df.dropna(axis=1, how=\"all\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing\n",
    "\n",
    "- Generate file paths for available CSV files in the Bronze layer.\n",
    "- Read and concatenate data from multiple files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T01:00:15.565044Z",
     "iopub.status.busy": "2025-04-19T01:00:15.564701Z",
     "iopub.status.idle": "2025-04-19T01:00:15.621432Z",
     "shell.execute_reply": "2025-04-19T01:00:15.620872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Files Detected => 5\n",
      "Processing file => /home/runner/work/PortfolioTracker/PortfolioTracker/DATA/BRONZE/TradeHistory/ptprashanttripathi/trade_2324.csv\n",
      "Processing file => /home/runner/work/PortfolioTracker/PortfolioTracker/DATA/BRONZE/TradeHistory/ptprashanttripathi/trade_2021.csv\n",
      "Processing file => /home/runner/work/PortfolioTracker/PortfolioTracker/DATA/BRONZE/TradeHistory/ptprashanttripathi/trade_2223.csv\n",
      "Processing file => /home/runner/work/PortfolioTracker/PortfolioTracker/DATA/BRONZE/TradeHistory/ptprashanttripathi/trade_2425.csv\n",
      "Processing file => /home/runner/work/PortfolioTracker/PortfolioTracker/DATA/BRONZE/TradeHistory/ptprashanttripathi/trade_2122.csv\n"
     ]
    }
   ],
   "source": [
    "# Generate file_paths\n",
    "file_paths = check_files_availability(\n",
    "    tradehistory_bronze_layer_path,\n",
    "    file_pattern=f\"{USERNAME}/trade_*.csv\",\n",
    ")\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through List of all CSV files in the folder\n",
    "for file_path in file_paths:\n",
    "    try:\n",
    "        # Read the CSV file\n",
    "        df = read_file(file_path)\n",
    "        # Append the DataFrame to the list\n",
    "        if not df.empty:\n",
    "            dfs.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to read {file_path} due to error => {e}\")\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "df_TradeHistory = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Harmonization\n",
    "\n",
    "- Replace scrip codes with company names using the SILVER layer symbol data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T01:00:15.623539Z",
     "iopub.status.busy": "2025-04-19T01:00:15.623185Z",
     "iopub.status.idle": "2025-04-19T01:00:15.661540Z",
     "shell.execute_reply": "2025-04-19T01:00:15.661041Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replace scrip code with company name\n",
    "df_Symbol = pd.read_csv(symbol_silver_file_path)\n",
    "\n",
    "# String and strip\n",
    "df_TradeHistory = df_TradeHistory.merge(\n",
    "    df_Symbol[[\"scrip_code\", \"symbol\"]],\n",
    "    left_on=\"scrip_code\",\n",
    "    right_on=\"scrip_code\",\n",
    "    how=\"left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Processing and Export\n",
    "\n",
    "- Sort the DataFrame by date and stock name.\n",
    "- Save the processed data as a CSV file in the Silver layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T01:00:15.663735Z",
     "iopub.status.busy": "2025-04-19T01:00:15.663396Z",
     "iopub.status.idle": "2025-04-19T01:00:15.672128Z",
     "shell.execute_reply": "2025-04-19T01:00:15.671552Z"
    }
   },
   "outputs": [],
   "source": [
    "# Group by the specified columns and sum 'amount' and 'quantity'\n",
    "df_TradeHistory = (\n",
    "    df_TradeHistory.groupby(\n",
    "        [\n",
    "            \"datetime\",\n",
    "            \"exchange\",\n",
    "            \"segment\",\n",
    "            \"symbol\",\n",
    "            \"scrip_name\",\n",
    "            \"side\",\n",
    "            \"price\",\n",
    "            \"expiry_date\",\n",
    "        ]\n",
    "    )\n",
    "    .agg({\"amount\": \"sum\", \"quantity\": \"sum\"})\n",
    "    .reset_index()\n",
    ")\n",
    "# TBD : NEED TO BE TESTED MORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T01:00:15.674197Z",
     "iopub.status.busy": "2025-04-19T01:00:15.673767Z",
     "iopub.status.idle": "2025-04-19T01:00:15.692798Z",
     "shell.execute_reply": "2025-04-19T01:00:15.692251Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataContract loaded from => /home/runner/work/PortfolioTracker/PortfolioTracker/CONFIG/DATA_CONTRACTS/SILVER/TradeHistory.json\n",
      "SILVER Layer CSV file for trade history successfully created at => /home/runner/work/PortfolioTracker/PortfolioTracker/DATA/SILVER/TradeHistory/ptprashanttripathi/TradeHistory_data.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 476 entries, 0 to 475\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   datetime     476 non-null    datetime64[ns]\n",
      " 1   exchange     476 non-null    string        \n",
      " 2   segment      476 non-null    string        \n",
      " 3   symbol       476 non-null    string        \n",
      " 4   scrip_name   476 non-null    string        \n",
      " 5   side         476 non-null    string        \n",
      " 6   amount       476 non-null    float64       \n",
      " 7   quantity     476 non-null    float64       \n",
      " 8   price        476 non-null    float64       \n",
      " 9   expiry_date  412 non-null    datetime64[ns]\n",
      "dtypes: datetime64[ns](2), float64(3), string(5)\n",
      "memory usage: 37.3 KB\n"
     ]
    }
   ],
   "source": [
    "# Align Datafame with DataContract\n",
    "df_TradeHistory = align_with_datacontract(\n",
    "    df_TradeHistory, tradehistory_silver_schema_file_path\n",
    ")\n",
    "\n",
    "# Save the result as a CSV file\n",
    "df_TradeHistory.to_csv(tradehistory_silver_file_path, index=None)\n",
    "print(\n",
    "    f\"SILVER Layer CSV file for trade history successfully created at => {tradehistory_silver_file_path}\"\n",
    ")\n",
    "\n",
    "# Log the DataFrame debug\n",
    "df_TradeHistory.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_debug": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
