{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BRONZE TO SILVER LAYER\n",
    "\n",
    "### Reading & Validate the Data from the Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T10:55:07.086679Z",
     "iopub.status.busy": "2024-09-04T10:55:07.086679Z",
     "iopub.status.idle": "2024-09-04T10:55:08.498246Z",
     "shell.execute_reply": "2024-09-04T10:55:08.497086Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries and utility functions\n",
    "import pandas as pd\n",
    "\n",
    "from ETLTools import GlobalPath, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T10:55:08.498246Z",
     "iopub.status.busy": "2024-09-04T10:55:08.498246Z",
     "iopub.status.idle": "2024-09-04T10:55:08.514369Z",
     "shell.execute_reply": "2024-09-04T10:55:08.512789Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate GlobalPath\n",
    "tradehistory_bronze_layer_path = GlobalPath(\"DATA/BRONZE/TradeHistory\")\n",
    "symbol_silver_file_path = GlobalPath(\"DATA/SILVER/Symbol/Symbol_data.csv\")\n",
    "tradehistory_silver_file_path = GlobalPath(\n",
    "    \"DATA/SILVER/TradeHistory/TradeHistory_data.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Definitions\n",
    "\n",
    "- **concat_company**: Concatenates stock names based on instrument type.\n",
    "- **read_file**: Reads and processes a CSV file from the Bronze layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T10:55:08.522674Z",
     "iopub.status.busy": "2024-09-04T10:55:08.520663Z",
     "iopub.status.idle": "2024-09-04T10:55:08.530378Z",
     "shell.execute_reply": "2024-09-04T10:55:08.530378Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to apply the conditional concatenation\n",
    "\n",
    "\n",
    "def get_scrip_name(row: pd.Series) -> str:\n",
    "    \"\"\"\n",
    "    Concatenate stock names based on the instrument type.\n",
    "\n",
    "    Parameters:\n",
    "    row (pd.Series): A row of DataFrame containing instrument data.\n",
    "\n",
    "    Returns:\n",
    "    str: The concatenated stock name.\n",
    "    \"\"\"\n",
    "    if row[\"instrument_type\"] == \"European Call\":\n",
    "        company = (\n",
    "            str(row[\"company\"])\n",
    "            + \"-CE-\"\n",
    "            + str(row[\"strike_price\"])\n",
    "            + \"-\"\n",
    "            + row[\"expiry\"]\n",
    "        )\n",
    "    elif row[\"instrument_type\"] == \"European Put\":\n",
    "        company = (\n",
    "            str(row[\"company\"])\n",
    "            + \"-PE-\"\n",
    "            + str(row[\"strike_price\"])\n",
    "            + \"-\"\n",
    "            + row[\"expiry\"]\n",
    "        )\n",
    "    else:\n",
    "        company = str(row[\"company\"])\n",
    "    return company.strip().upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T10:55:08.536857Z",
     "iopub.status.busy": "2024-09-04T10:55:08.530378Z",
     "iopub.status.idle": "2024-09-04T10:55:08.550471Z",
     "shell.execute_reply": "2024-09-04T10:55:08.550471Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to read and process a CSV file\n",
    "\n",
    "\n",
    "def read_file(file_path: GlobalPath):\n",
    "    \"\"\"\n",
    "    Reads and processes a CSV file from the Bronze layer.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The processed DataFrame.\n",
    "    \"\"\"\n",
    "    print(f\"Processing file: {file_path}\")\n",
    "\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = utils.replace_punctuation_from_columns(df)\n",
    "\n",
    "    # Convert 'trade_num' to int\n",
    "    df[\"trade_num\"] = df[\"trade_num\"].fillna(0).astype(int)\n",
    "\n",
    "    # Add Datetime Col\n",
    "    df[\"datetime\"] = pd.to_datetime(\n",
    "        df[\"date\"].str.replace(\"00:00:00\", \"\").str.strip()\n",
    "        + \" \"\n",
    "        + df[\"trade_time\"].fillna(\"00:00:00\"),\n",
    "        format=\"%Y-%m-%d %H:%M:%S\",\n",
    "    )\n",
    "\n",
    "    # Convert 'expiry' to desired string format\n",
    "    df[\"expiry_date\"] = pd.to_datetime(df[\"expiry\"], format=\"%d-%m-%Y\")\n",
    "    df[\"expiry\"] = df[\"expiry_date\"].dt.strftime(\"%d%b%Y\")\n",
    "\n",
    "    # Convert the 'side' column in df to uppercase\n",
    "    df[\"side\"] = df[\"side\"].astype(str).str.strip().str.upper()\n",
    "\n",
    "    # Add the \"IN\" prefix to 'scrip_code'\n",
    "    df[\"scrip_code\"] = (\n",
    "        \"IN\" + df[\"scrip_code\"].astype(str).str.strip().str.upper()\n",
    "    )\n",
    "\n",
    "    # Apply the function to the DataFrame\n",
    "    df[\"scrip_name\"] = df.apply(get_scrip_name, axis=1)\n",
    "\n",
    "    # Remove all-NA columns from each DataFrame\n",
    "    df = df.dropna(axis=1, how=\"all\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing\n",
    "\n",
    "- Generate file paths for available CSV files in the Bronze layer.\n",
    "- Read and concatenate data from multiple files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T10:55:08.556521Z",
     "iopub.status.busy": "2024-09-04T10:55:08.556521Z",
     "iopub.status.idle": "2024-09-04T10:55:08.638521Z",
     "shell.execute_reply": "2024-09-04T10:55:08.638521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Files Detected: 5\n",
      "Processing file: /workspaces/PortfolioTracker/DATA/BRONZE/TradeHistory/trade_2223.csv\n",
      "Processing file: /workspaces/PortfolioTracker/DATA/BRONZE/TradeHistory/trade_2324.csv\n",
      "Processing file: /workspaces/PortfolioTracker/DATA/BRONZE/TradeHistory/trade_2021.csv\n",
      "Processing file: /workspaces/PortfolioTracker/DATA/BRONZE/TradeHistory/trade_2122.csv\n",
      "Processing file: /workspaces/PortfolioTracker/DATA/BRONZE/TradeHistory/trade_2425.csv\n"
     ]
    }
   ],
   "source": [
    "# Generate file_paths\n",
    "file_paths = tradehistory_bronze_layer_path.check_files_availability(\n",
    "    file_pattern=\"trade_*.csv\",\n",
    ")\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through List of all CSV files in the folder\n",
    "for file_path in file_paths:\n",
    "    try:\n",
    "        # Read the CSV file\n",
    "        df = read_file(file_path)\n",
    "        # Append the DataFrame to the list\n",
    "        if not df.empty:\n",
    "            dfs.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to read {file_path} due to error: {e}\")\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "df_TradeHistory = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Harmonization\n",
    "\n",
    "- Replace scrip codes with company names using the SILVER layer symbol data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T10:55:08.646011Z",
     "iopub.status.busy": "2024-09-04T10:55:08.638521Z",
     "iopub.status.idle": "2024-09-04T10:55:08.740753Z",
     "shell.execute_reply": "2024-09-04T10:55:08.740753Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid file path or buffer object type: <class 'ETLTools.globalpath.GlobalPath'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Replace scrip code with company name\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_Symbol \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbol_silver_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# String and strip\u001b[39;00m\n\u001b[1;32m      5\u001b[0m df_TradeHistory \u001b[38;5;241m=\u001b[39m df_TradeHistory\u001b[38;5;241m.\u001b[39mmerge(\n\u001b[1;32m      6\u001b[0m     df_Symbol[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscrip_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msymbol\u001b[39m\u001b[38;5;124m\"\u001b[39m]],\n\u001b[1;32m      7\u001b[0m     left_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscrip_code\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     right_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscrip_code\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m     how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/common.py:728\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    725\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[0;32m--> 728\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    736\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[1;32m    737\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/io/common.py:472\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(filepath_or_buffer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(filepath_or_buffer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    470\u001b[0m ):\n\u001b[1;32m    471\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid file path or buffer object type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(filepath_or_buffer)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 472\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m IOArgs(\n\u001b[1;32m    475\u001b[0m     filepath_or_buffer\u001b[38;5;241m=\u001b[39mfilepath_or_buffer,\n\u001b[1;32m    476\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    479\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m    480\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid file path or buffer object type: <class 'ETLTools.globalpath.GlobalPath'>"
     ]
    }
   ],
   "source": [
    "# Replace scrip code with company name\n",
    "df_Symbol = pd.read_csv(symbol_silver_file_path)\n",
    "\n",
    "# String and strip\n",
    "df_TradeHistory = df_TradeHistory.merge(\n",
    "    df_Symbol[[\"scrip_code\", \"symbol\"]],\n",
    "    left_on=\"scrip_code\",\n",
    "    right_on=\"scrip_code\",\n",
    "    how=\"left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Processing and Export\n",
    "\n",
    "- Sort the DataFrame by date and stock name.\n",
    "- Save the processed data as a CSV file in the Silver layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T10:55:08.745268Z",
     "iopub.status.busy": "2024-09-04T10:55:08.745268Z",
     "iopub.status.idle": "2024-09-04T10:55:08.773977Z",
     "shell.execute_reply": "2024-09-04T10:55:08.773977Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMAINING COLUMNS :"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {'trade_num', 'strike_price', 'date', 'trade_time', 'scrip_code', 'company', 'instrument_type', 'expiry'}\n",
      "SILVER Layer CSV file for trade history successfully created at:\n",
      "DATA/SILVER/TradeHistory/TradeHistory_data.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 287 entries, 17 to 42\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   datetime     287 non-null    datetime64[ns]\n",
      " 1   exchange     287 non-null    object        \n",
      " 2   segment      287 non-null    object        \n",
      " 3   symbol       287 non-null    object        \n",
      " 4   scrip_name   287 non-null    object        \n",
      " 5   side         287 non-null    object        \n",
      " 6   amount       287 non-null    float64       \n",
      " 7   quantity     287 non-null    float64       \n",
      " 8   price        287 non-null    float64       \n",
      " 9   expiry_date  237 non-null    datetime64[ns]\n",
      "dtypes: datetime64[ns](2), float64(3), object(5)\n",
      "memory usage: 24.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Sort the DataFrame by date and stock name\n",
    "df_TradeHistory = df_TradeHistory.sort_values(by=[\"datetime\"])  # , \"company\"\n",
    "\n",
    "# Select relevant columns\n",
    "relevant_columns = [\n",
    "    \"datetime\",\n",
    "    \"exchange\",\n",
    "    \"segment\",\n",
    "    \"symbol\",\n",
    "    \"scrip_name\",\n",
    "    \"side\",\n",
    "    \"amount\",\n",
    "    \"quantity\",\n",
    "    \"price\",\n",
    "    \"expiry_date\",\n",
    "]\n",
    "print(\n",
    "    \"REMAINING COLUMNS :\", set(df_TradeHistory.columns) - set(relevant_columns)\n",
    ")\n",
    "df_TradeHistory = df_TradeHistory[relevant_columns]\n",
    "\n",
    "# Save the result as a CSV file\n",
    "df_TradeHistory.to_csv(tradehistory_silver_file_path.path, index=None)\n",
    "print(\"SILVER Layer CSV file for trade history successfully created at:\")\n",
    "print(tradehistory_silver_file_path)\n",
    "# Log the DataFrame debug\n",
    "df_TradeHistory.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_debug": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
