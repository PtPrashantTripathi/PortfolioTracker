{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, datetime, re, copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options = webdriver.ChromeOptions()\n",
    "# options.add_argument(\"--start-maximized\")\n",
    "# prefs = {\n",
    "#     \"profile.default_content_settings.popups\": 0,\n",
    "#     \"download.default_directory\": \"./\",\n",
    "#     \"directory_upgrade\": True,\n",
    "# }\n",
    "# options.add_experimental_option(\"prefs\", prefs)\n",
    "# browser = webdriver.Chrome(options=options)\n",
    "\n",
    "# split_url = \"http://www.moneycontrol.com/stocks/marketinfo/splits/index.php?sel_year=\"\n",
    "# bonus_url = \"http://www.moneycontrol.com/stocks/marketinfo/bonus/index.php?sel_year=\"\n",
    "# url = [split_url, bonus_url]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "      <th>qty</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8KMILES</td>\n",
       "      <td>2017-11-08</td>\n",
       "      <td>S</td>\n",
       "      <td>28</td>\n",
       "      <td>763.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8KMILES</td>\n",
       "      <td>2017-11-08</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>763.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8KMILES</td>\n",
       "      <td>2017-11-06</td>\n",
       "      <td>B</td>\n",
       "      <td>5</td>\n",
       "      <td>842.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8KMILES</td>\n",
       "      <td>2017-11-03</td>\n",
       "      <td>B</td>\n",
       "      <td>5</td>\n",
       "      <td>884.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8KMILES</td>\n",
       "      <td>2017-10-26</td>\n",
       "      <td>B</td>\n",
       "      <td>10</td>\n",
       "      <td>544.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    symbol        date type  qty   rate\n",
       "0  8KMILES  2017-11-08    S   28  763.0\n",
       "1  8KMILES  2017-11-08    S    2  763.0\n",
       "2  8KMILES  2017-11-06    B    5  842.5\n",
       "3  8KMILES  2017-11-03    B    5  884.0\n",
       "4  8KMILES  2017-10-26    B   10  544.7"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tradeDF =  pd.read_csv(\"TRADEBOOK.csv\")\n",
    "years = np.unique(pd.to_datetime(tradeDF[\"date\"]).dt.year)\n",
    "tradeDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2017, 2018])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# years = np.append(years, datetime.datetime.today().year)\n",
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getBseCorpAct(browser):\n",
    "#     browser.get(\"https://www.bseindia.com/corporates/corporate_act.aspx\")\n",
    "\n",
    "#     browser.find_element_by_name(\"ctl00$ContentPlaceHolder1$txtDate\").click()\n",
    "#     browser.execute_script(\"javascript:setCalendarControlDate(\" + str(years[0]) + \",1,1)\")\n",
    "\n",
    "#     browser.find_element_by_name(\"ctl00$ContentPlaceHolder1$txtTodate\").click()\n",
    "#     browser.execute_script(\"javascript:setCalendarControlDate(\" + str(yearT) + \",\" + str(monthT).lstrip(\"0\") + \",\" + str(dayT).lstrip(\"0\") + \")\")\n",
    "\n",
    "#     browser.find_element_by_name(\"ctl00$ContentPlaceHolder1$btnSubmit\").click()\n",
    "#     # directly downloads to preferref location set in driver preferences\n",
    "#     browser.execute_script(\"javascript:__doPostBack('ctl00$ContentPlaceHolder1$lnkDownload','')\")\n",
    "#     while \"Corporate_Actions.csv\" not in os.listdir():\n",
    "#         time.sleep(1)\n",
    "#     # data = pd.read_csv(directory + \"Corporate_Actions.csv\", index_col = None)\n",
    "#     data = pd.read_csv(\"./Corporate_Actions.csv\", index_col=None)\n",
    "#     data.columns = [x.lower().replace(\" \", \"_\").replace(\"\\t\", \"\") for x in data.columns]\n",
    "#     data[\"purpose\"] = data.purpose.apply(lambda x: x.lower())\n",
    "#     data = data[[True if \"split\" in x or \"bonus\" in x else False for x in data[\"purpose\"]]]\n",
    "#     data.reset_index(drop=True, inplace=True)\n",
    "#     # data.to_csv(directory + \"Corporate_Actions.csv\", index = None)\n",
    "#     data.to_csv(\"./Corporate_Actions.csv\", index=None)\n",
    "\n",
    "\n",
    "# def getIDentifiers(link, browser):\n",
    "#     print(len([x for x in link.split(\"/\") if x != \"\"]))\n",
    "#     if len([x for x in link.split(\"/\") if x != \"\"]) != 7:\n",
    "#         return pd.DataFrame([[np.nan] * 4], columns=[\"bse\", \"nse\", \"isin\", \"sector\"])\n",
    "#     browser.get(link)\n",
    "#     print(link)\n",
    "#     time.sleep(2)\n",
    "#     idList = browser.find_element_by_xpath('//div[@class = \"FL gry10\"]').text.split(\"|\")[:-1]\n",
    "#     idList = [x.strip().split(\":\") for x in idList]\n",
    "#     return pd.DataFrame.from_dict({val[0].strip().lower(): [val[1].strip()] for val in idList})\n",
    "\n",
    "\n",
    "# def getCorpActData(url, years, act):\n",
    "#     i = 0\n",
    "#     mssg = \"Getting Data for Splits\"\n",
    "#     if act == \"Bonus\":\n",
    "#         i = 1\n",
    "#         mssg = \"Getting Data for Bonus\"\n",
    "#     final_df = None\n",
    "#     for year in years:\n",
    "#         print(mssg)\n",
    "#         link = url[i] + str(year)\n",
    "#         browser.get(link)\n",
    "#         time.sleep(3)\n",
    "#         content = browser.find_element_by_xpath('//div[@class=\"MT15\"]/table[@class=\"b_12 dvdtbl tbldata14\"]').get_attribute(\"outerHTML\")\n",
    "#         links = browser.find_elements_by_xpath('//div[@class=\"MT15\"]/table[@class=\"b_12 dvdtbl tbldata14\"]//td[@class=\"dvd_brdb\"]/a')\n",
    "#         links = [x.get_attribute(\"href\") for x in links]\n",
    "#         links = links\n",
    "#         df = pd.read_html(content)[0]\n",
    "#         if i == 0:\n",
    "#             df.drop([0], inplace=True)\n",
    "#             df.reset_index(drop=True, inplace=True)\n",
    "#             df.columns = [\"company\", \"old\", \"new\", \"split_date\"]\n",
    "#             idListDf = [getIDentifiers(x, browser) for x in links]\n",
    "#             idDf = pd.concat(idListDf, axis=0)\n",
    "#             idDf.reset_index(drop=True, inplace=True)\n",
    "#             df = pd.concat([df, idDf], axis=1)\n",
    "#         else:\n",
    "#             df.drop([0, 1], inplace=True)\n",
    "#             df.reset_index(drop=True, inplace=True)\n",
    "#             df.columns = [\"company\", \"bonus_ratio\", \"ex_bonus_date\", \"announcement_date\", \"record_date\"]\n",
    "#             bonusDf = pd.DataFrame(df[\"bonus_ratio\"].apply(lambda x: x.split(\":\")).tolist(), columns=[\"old\", \"new\"])\n",
    "#             df = pd.concat([df, bonusDf], axis=1)\n",
    "#             idListDf = [getIDentifiers(x, browser) for x in links]\n",
    "#             idDf = pd.concat(idListDf, axis=0)\n",
    "#             idDf.reset_index(drop=True, inplace=True)\n",
    "#             df = pd.concat([df, idDf], axis=1)\n",
    "#         df[\"company\"] = df[\"company\"].apply(lambda x: str(x).replace(\"  Add to Watchlist  Add to Portfolio\", \"\"))\n",
    "#         final_df = pd.concat([final_df, df], axis=0)\n",
    "#     return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjustmentCalculator(data, typeOf, old, new):\n",
    "    if typeOf == \"split\":\n",
    "        data[\"rate\"] = data[\"rate\"] * (new / old)\n",
    "        data[\"qty\"] = data[\"qty\"] * (old / new)\n",
    "    elif typeOf == \"bonus\":  # will include other as well soon like reverse split\n",
    "        cols = list(data.columns)\n",
    "        data[\"remainder\"] = [x % new for x in data[\"qty\"]]\n",
    "        data[\"quotient\"] = [int(x / new) for x in data[\"qty\"]]\n",
    "        data[\"rate\"] = data[\"qty\"] * data[\"rate\"] / (data[\"qty\"] + data[\"quotient\"])\n",
    "        data[\"qty\"] = data[\"qty\"] + data[\"quotient\"]\n",
    "        data = data[cols]\n",
    "    return data\n",
    "\n",
    "\n",
    "def pnlCalculator(data):\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    # Declaring variables to calc pnl\n",
    "    buy_avg = 0\n",
    "    buy_pos = 0\n",
    "    sell_avg = 0\n",
    "    sell_pos = 0\n",
    "    realized_profit = []\n",
    "\n",
    "    # out of tuple of index and row, choose row and select a column\n",
    "    # print(np.unique(data['type']))\n",
    "    # print(len(list(groupby(data.iterrows(), key=lambda row: row[1]['type']))))\n",
    "    for i, (k, l) in enumerate(groupby(data.iterrows(), key=lambda row: row[1][\"type\"])):\n",
    "        sub_df = data.iloc[[t[0] for t in l], :]\n",
    "        # print(i,k,sub_df)\n",
    "        sub_df.reset_index(inplace=True, drop=True)\n",
    "        # print(i,k)\n",
    "        if i == 0:\n",
    "            if k == \"B\":\n",
    "                buy_pos = sum(sub_df[\"qty\"])\n",
    "                buy_avg = sum(sub_df[\"qty\"] * sub_df[\"rate\"]) / buy_pos\n",
    "            else:\n",
    "                sell_pos = sum(sub_df[\"qty\"])\n",
    "                sell_avg = sum(sub_df[\"qty\"] * sub_df[\"rate\"]) / sell_pos\n",
    "        elif k == \"B\":\n",
    "            if sell_pos > 0:  # intraday trades\n",
    "                assert buy_pos == 0\n",
    "                # print(\"Was here Buy\")\n",
    "                if (sell_pos - sum(sub_df[\"qty\"])) >= 0:\n",
    "                    sell_pos -= sum(sub_df[\"qty\"])\n",
    "                    buy_avg = sum(sub_df[\"qty\"] * sub_df[\"rate\"]) / sum(sub_df[\"qty\"])\n",
    "                    # realized_profit\n",
    "                    try:\n",
    "                        realized_profit.append((sum(sub_df[\"qty\"])) * (sell_avg - buy_avg))\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "                else:\n",
    "                    sub_df[\"cum_qty\"] = sell_pos - sub_df[\"qty\"].cumsum()\n",
    "                    minIndex = np.min(np.where(sub_df[\"cum_qty\"] <= 0))\n",
    "\n",
    "                    df1 = sub_df[: minIndex + 1].reset_index(drop=True)\n",
    "                    df1.iloc[-1, df1.columns.get_loc(\"qty\")] = int(df1.tail(1)[\"qty\"] + df1.tail(1)[\"cum_qty\"])\n",
    "                    buy_avg = sum(df1[\"qty\"] * df1[\"rate\"]) / sum(df1[\"qty\"])\n",
    "\n",
    "                    # realized_profit\n",
    "                    try:\n",
    "                        realized_profit.append((sum(df1[\"qty\"])) * (sell_avg - buy_avg))\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "\n",
    "                    df2 = sub_df[minIndex:].reset_index(drop=True)\n",
    "                    df2.iloc[0, df2.columns.get_loc(\"qty\")] = int(-1 * df2.head(1)[\"cum_qty\"])\n",
    "                    buy_avg = sum(df2[\"qty\"] * df2[\"rate\"]) / sum(df2[\"qty\"])\n",
    "\n",
    "                    buy_pos = sum(sub_df[\"qty\"]) - sell_pos\n",
    "                    sell_pos = 0\n",
    "\n",
    "            else:\n",
    "                buy_avg = (sum(sub_df[\"qty\"] * sub_df[\"rate\"]) + buy_avg * buy_pos) / (buy_pos + sum(sub_df[\"qty\"]))\n",
    "                buy_pos = buy_pos + sum(sub_df[\"qty\"])\n",
    "\n",
    "        elif k == \"S\":\n",
    "            if buy_pos > 0:\n",
    "                assert sell_pos == 0\n",
    "                # print(\"Was here Sell\")\n",
    "                if (buy_pos - sum(sub_df[\"qty\"])) >= 0:\n",
    "                    buy_pos -= sum(sub_df[\"qty\"])\n",
    "                    sell_avg = sum(sub_df[\"qty\"] * sub_df[\"rate\"]) / sum(sub_df[\"qty\"])\n",
    "                    # realized_profit\n",
    "                    try:\n",
    "                        realized_profit.append((sum(sub_df[\"qty\"])) * (sell_avg - buy_avg))\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "                else:\n",
    "                    sub_df[\"cum_qty\"] = buy_pos - sub_df[\"qty\"].cumsum()\n",
    "                    minIndex = np.min(np.where(sub_df[\"cum_qty\"] <= 0))\n",
    "\n",
    "                    df1 = sub_df[: minIndex + 1].reset_index(drop=True)\n",
    "                    df1.iloc[-1, df1.columns.get_loc(\"qty\")] = int(df1.tail(1)[\"qty\"] + df1.tail(1)[\"cum_qty\"])\n",
    "                    sell_avg = sum(df1[\"qty\"] * df1[\"rate\"]) / sum(df1[\"qty\"])\n",
    "\n",
    "                    # realized_profit\n",
    "                    try:\n",
    "                        realized_profit.append((sum(df1[\"qty\"])) * (sell_avg - buy_avg))\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "\n",
    "                    df2 = sub_df[minIndex:].reset_index(drop=True)\n",
    "                    df2.iloc[0, df2.columns.get_loc(\"qty\")] = int(-1 * df2.head(1)[\"cum_qty\"])\n",
    "                    sell_avg = sum(df2[\"qty\"] * df2[\"rate\"]) / sum(df2[\"qty\"])\n",
    "\n",
    "                    sell_pos = sum(sub_df[\"qty\"]) - buy_pos\n",
    "                    buy_pos = 0\n",
    "            else:\n",
    "                sell_avg = (sum(sub_df[\"qty\"] * sub_df[\"rate\"]) + sell_avg * sell_pos) / (sell_pos + sum(sub_df[\"qty\"]))\n",
    "                sell_pos = sell_pos + sum(sub_df[\"qty\"])\n",
    "\n",
    "    return sum(realized_profit)\n",
    "\n",
    "\n",
    "# splitDF = getCorpActData(url, years, \"Split\")\n",
    "# splitDF.to_csv(directory + \"split.csv\", index = None)\n",
    "# splitDF.to_csv(\"./split.csv\", index = None)\n",
    "# bonusDF = getCorpActData(url, years, \"Bonus\")\n",
    "# bonusDF.to_csv(\"./bonus.csv\", index = None)\n",
    "getBseCorpAct(browser)\n",
    "\n",
    "# Loading the datasets\n",
    "# splitDF = pd.read_csv(directory + \"split.csv\", index_col = None)\n",
    "splitDF = pd.read_csv(\"./split.csv\", index_col=None)\n",
    "splitDF[\"split_date\"] = pd.to_datetime(splitDF[\"split_date\"], format=\"%d-%m-%Y\").dt.date\n",
    "# Keep only records where we have nse symbol, getting bse symbol from bse website\n",
    "splitDF.dropna(axis=0, subset=[\"nse\"], inplace=True)\n",
    "splitDF.reset_index(drop=True, inplace=True)\n",
    "splitDF = splitDF[[\"nse\", \"split_date\", \"old\", \"new\"]]\n",
    "splitDF.columns = [\"symbol\", \"date\", \"old\", \"new\"]\n",
    "splitDF[\"type\"] = \"split\"\n",
    "\n",
    "\n",
    "# bonusDF = pd.read_csv(directory + \"bonus.csv\", index_col = None)\n",
    "bonusDF = pd.read_csv(\"./bonus.csv\", index_col=None)\n",
    "bonusDF[\"split_date\"] = pd.to_datetime(bonusDF[\"record_date\"], format=\"%d-%m-%Y\").dt.date\n",
    "# Keep only records where we have nse symbol, getting bse symbol from bse website\n",
    "bonusDF.dropna(axis=0, subset=[\"nse\"], inplace=True)\n",
    "bonusDF.reset_index(drop=True, inplace=True)\n",
    "bonusDF = bonusDF[[\"nse\", \"split_date\", \"old\", \"new\"]]\n",
    "bonusDF.columns = [\"symbol\", \"date\", \"old\", \"new\"]\n",
    "bonusDF[\"type\"] = \"bonus\"\n",
    "\n",
    "\n",
    "# bseCorpDF = pd.read_csv(directory + \"Corporate_Actions.csv\", index_col = None)\n",
    "bseCorpDF = pd.read_csv(\"./Corporate_Actions.csv\", index_col=None)\n",
    "bseCorpDF[\"ex_date_form\"] = pd.to_datetime(bseCorpDF[\"ex_date\"], format=\"%d %b %Y\").dt.date\n",
    "\n",
    "# Creating split and bonuses\n",
    "bseCorpSplitDf = bseCorpDF[[\"split\" in x for x in bseCorpDF.purpose]]\n",
    "bseCorpSplitDf.reset_index(drop=True, inplace=True)\n",
    "bseCorpSplitDf = bseCorpSplitDf[[\"security_name\", \"ex_date_form\", \"purpose\"]]\n",
    "old_new = pd.DataFrame(bseCorpSplitDf.purpose.apply(lambda x: re.findall(r\"\\d+\", x)[-2:]).tolist(), columns=[\"old\", \"new\"])\n",
    "bseCorpSplitDf = pd.concat([bseCorpSplitDf, old_new], axis=1)\n",
    "bseCorpSplitDf = bseCorpSplitDf[[\"security_name\", \"ex_date_form\", \"old\", \"new\"]]\n",
    "bseCorpSplitDf.columns = [\"symbol\", \"date\", \"old\", \"new\"]\n",
    "bseCorpSplitDf[\"type\"] = \"split\"\n",
    "\n",
    "bseCorpBonusDf = bseCorpDF[[\"bonus\" in x for x in bseCorpDF.purpose]]\n",
    "bseCorpBonusDf.reset_index(drop=True, inplace=True)\n",
    "bseCorpBonusDf = bseCorpBonusDf[[\"security_name\", \"ex_date_form\", \"purpose\"]]\n",
    "old_new = pd.DataFrame(bseCorpBonusDf.purpose.apply(lambda x: re.findall(r\"\\d+\", x)[:2]).tolist(), columns=[\"old\", \"new\"])\n",
    "bseCorpBonusDf = pd.concat([bseCorpBonusDf, old_new], axis=1)\n",
    "bseCorpBonusDf = bseCorpBonusDf[[\"security_name\", \"ex_date_form\", \"old\", \"new\"]]\n",
    "bseCorpBonusDf.columns = [\"symbol\", \"date\", \"old\", \"new\"]\n",
    "bseCorpBonusDf[\"type\"] = \"bonus\"\n",
    "\n",
    "\n",
    "corpAcDF = pd.concat([splitDF, bseCorpSplitDf, bonusDF, bseCorpBonusDf], axis=0, ignore_index=True)\n",
    "corpAcDF[\"symbol\"] = [x.strip() for x in corpAcDF[\"symbol\"]]\n",
    "corpAcDF[\"old\"] = [int(x) for x in corpAcDF[\"old\"]]\n",
    "corpAcDF[\"new\"] = [int(x) for x in corpAcDF[\"new\"]]\n",
    "corpAcDF.drop_duplicates(inplace=True)\n",
    "corpAcDF.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Getting unique symbols in my list and adjusting them for corporate action\n",
    "symbols = np.unique(tradeDF.symbol)\n",
    "symbolGroup = tradeDF.groupby([\"symbol\"])\n",
    "symbolsCorpAcGroup = corpAcDF.groupby([\"symbol\"])\n",
    "\n",
    "symbolGroupDict = {}\n",
    "for symbol in symbols:\n",
    "    print(symbol)\n",
    "    # Tradebook\n",
    "    df = symbolGroup.get_group(symbol)\n",
    "    df.sort_values(\"date\", inplace=True)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    if len(np.unique(df[\"type\"])) > 1:\n",
    "        # print(symbol,\"Length Greater\")\n",
    "        if any([symbol in x for x in corpAcDF[\"symbol\"]]):\n",
    "            try:\n",
    "                dfCorp = symbolsCorpAcGroup.get_group(symbol)\n",
    "            except KeyError as e:\n",
    "                symbolGroupDict[symbol] = pnlCalculator(data=df)\n",
    "                continue\n",
    "            # corporate Action\n",
    "            dfCorp.sort_values(\"date\", inplace=True)\n",
    "            dfCorp.reset_index(inplace=True, drop=True)\n",
    "            for _, row in dfCorp.iterrows():\n",
    "                try:\n",
    "                    tillIndex = np.min(np.where(df.date == row[\"date\"]))\n",
    "                except ValueError as e:\n",
    "                    continue\n",
    "                data = df.iloc[:tillIndex].reset_index(drop=True)\n",
    "                data = adjustmentCalculator(data, row[\"type\"], row[\"old\"], row[\"new\"])\n",
    "                df.iloc[:tillIndex] = data\n",
    "\n",
    "        symbolGroupDict[symbol] = pnlCalculator(data=df)\n",
    "    else:\n",
    "        # print(symbol,\"Length Lower\")\n",
    "        symbolGroupDict[symbol] = None\n",
    "\n",
    "pnlData = pd.DataFrame.from_dict(symbolGroupDict, orient=\"index\")\n",
    "pnlData[\"symbol\"] = pnlData.index\n",
    "pnlData.columns = [\"realized_profit\", \"symbol\"]\n",
    "pnlData.to_csv(\"./result_pnl_output.csv\", index=None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
